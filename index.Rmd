---
title: "Diagnostics Supplemental Material"
author: "Jose Guadalupe Hernandez"
date: "`r Sys.Date()`"
output: bookdown::gitbook
documentclass: book
bibliography: ["book.bib", "packages.bib"]
biblio-style: apalike
nocite: '@*'
link-citations: yes
github-repo:  jgh9094/ECJ-2022-suite-of-diagnostics-for-selection-schemes
description: "This is a demo for automatically deploying your bookdown ebook to GitHub pages."
---

```{r init, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# knitr::opts_knit$set(root.dir = "/mnt/c/Users/jgh9094/Desktop/Research/Projects/SelectionDiagnostics/Selection-Scheme-Diagnotics-Part-I")
# knitr::opts_knit$set(root.dir = "/opt/ECJ-2022-suite-of-diagnostics-for-selection-schemes/")
# getwd()
```

# Introduction

This is the supplemental material associated with our 2022 ECJ contribution entitled, _A suite of diagnostic metrics for characterizing selection schemes_.
Preprint [here](https://arxiv.org/pdf/2204.13839.pdf).

## About our supplemental material

This supplemental material is hosted on [GitHub](https://github.com) using GitHub pages.
The source code and configuration files used to generate this supplemental material can be found in [this GitHub repository](https://github.com/jgh9094/ECJ-2022-suite-of-diagnostics-for-selection-schemes).
We compiled our data analyses and supplemental documentation into this nifty web-accessible book using [bookdown](https://bookdown.org/).

Our supplemental material includes the following paper figures and statistics:

- Exploitation rate results (Section \@ref(exploitation-rate-results))
- Ordered exploitation results (Section \@ref(ordered-exploitation-results))
- Contradictory objectives results (Section \@ref(contradictory-objectives-results))
- Multi-path exploration results (Section \@ref(multi-path-exploration-results))

Additionally, our supplemental material includes the results from parameter tuning selection schemes:

- Truncation selection (Section \@ref(truncation-selection))
- Tournament selection sharing (Section \@ref(tournament-selection))
- Genotypic fitness sharing (Section \@ref(genotypic-fitness-sharing))
- Phenotypic fitness sharing (Section \@ref(phenotypic-fitness-sharing))
- Nondominated sorting (Section \@ref(nondominated-sorting))
- Novelty search (Section \@ref(novelty-search))

## Contributing authors

- [Jose Guadalupe Hernandez](https://jgh9094.github.io/)
- [Alexander Lalejini](https://lalejini.com)
- [Charles Ofria](http://ofria.com)

## Research overview

Abstract:

Evolutionary algorithms are effective general-purpose techniques for solving optimization problems.
Typically, evolutionary algorithms consist of multiple interacting components, where each component influences an algorithm's problem-solving abilities.
Understanding how each component of an evolutionary algorithm influences its problem-solving success improves our ability to target particular problem domains.
Benchmark suites provide insights into an evolutionary algorithm's problem-solving capabilities, but benchmarking problems often have complex search space topologies, making it difficult to isolate and test an algorithm's strengths and weaknesses.
Our work focuses on diagnosing selection schemes, which identity individuals to contribute genetic material to the next generation, thus driving an evolutionary algorithm's search strategy.
We introduce four diagnostics for empirically testing the strengths and weaknesses of selection schemes: the exploitation rate diagnostic, ordered exploitation rate diagnostic, contradictory objectives diagnostic, and the multi-path exploration diagnostic.
Each diagnostic is a handcrafted search space designed to isolate and measure the relative exploitation and exploration characteristics of selection schemes.
Here, we use our diagnostics to evaluate six population selection methods: truncation selection, tournament selection, fitness sharing, lexicase selection, nondominated sorting, and novelty search.
Expectedly, tournament and truncation selection excelled at gradient exploitation but poorly explored search spaces, and novelty search excelled at exploration but failed to exploit fitness gradients.
Fitness sharing performed poorly across all diagnostics, suggesting poor overall exploitation and exploration abilities.
Nondominated sorting was best for maintaining diverse populations comprised of individuals inhabiting multiple optima, but struggled to effectively exploit fitness gradients.
Lexicase selection balanced search space exploration with exploitation, generally performing well across diagnostics.
Our work demonstrates the value of diagnostic search spaces for building a deeper understanding of selection schemes, which can then be used to improve or develop new selection methods.

## Experimental setup

Setting up required variables variables.

```{r setup}
library(ggplot2)
library(dplyr)

# variables used throughout

TRAITS = 100
TSIZE = 26
ORDER = c('Truncation (tru)','Tournament (tor)', 'Genotypic Fitness Sharing (gfs)','Phenotypic Fitness Sharing (pfs)','Lexicase (lex)','Nondominated Sorting (nds)','Novelty Search (nov)','Random (ran)')
ACRON = tolower(c('TRU','TOR','GFS','PFS','LEX','NDS','NOV','RAN'))
SHAPE = c(5,3,2,6,1,0,4,20,1)
PARAM = c('8', '8', '0.3', '0.3', '0.0', '0.3', '15', '1')
cb_palette <- c('#332288','#88CCEE','#EE3377','#117733','#EE7733','#882255','#44AA99','#CCBB44', '#000000')

# selection scheme parameters

TR_LIST = c(1, 2, 4, 8, 16, 32, 64, 128, 256)
TS_LIST = c(2, 4, 8, 16, 32, 64, 128, 256)
FS_LIST = c(0.0, 0.1, 0.3, 0.6, 1.2, 2.5, 5.0)
ND_LIST = c(0.0, 0.1, 0.3, 0.6, 1.2, 2.5, 5.0)
NS_LIST = c(1, 2, 4, 8, 15, 30)

# theme that graphs will follow

p_theme <- theme(
  text = element_text(size = 28),
  plot.title = element_text( face = "bold", size = 22, hjust=0.5),
  panel.border = element_blank(),
  panel.grid.minor = element_blank(),
  legend.title=element_text(size=18),
  legend.text=element_text(size=14),
  axis.title = element_text(size=18),
  axis.text = element_text(size=16),
  legend.position="bottom",
  panel.background = element_rect(fill = "#f1f2f5",
                                  colour = "white",
                                  size = 0.5, linetype = "solid")
)

# cross comparison data frames

cc_over_time <- read.csv('./DATA-FINAL/POLISHED/cross-comp-over-time.csv', header = TRUE, stringsAsFactors = FALSE)
colnames(cc_over_time)[19] <- 'Selection\nScheme'
cc_over_time$`Selection\nScheme` <- factor(cc_over_time$`Selection\nScheme`, levels = ORDER)
cc_best = read.csv('./DATA-FINAL/POLISHED/cross-comp-best.csv', header = TRUE, stringsAsFactors = FALSE)
cc_best$acron <- factor(cc_best$acron, levels = ACRON)
cc_ssf = read.csv('./DATA-FINAL/POLISHED/selection-scheme-ssf.csv', header = TRUE, stringsAsFactors = FALSE)
cc_ssf$acron <- factor(cc_ssf$acron, levels = ACRON)
cc_ssf[is.na(cc_ssf)] <- 59999
cc_end <- filter(cc_over_time, gen == 50000)
cc_end$acron <- factor(cc_end$acron, levels = ACRON)



# selection scheme data frames

ss_over_time <- read.csv('./DATA-FINAL/POLISHED/selection-scheme-over-time.csv', header = TRUE, stringsAsFactors = FALSE)
ss_best <- read.csv('./DATA-FINAL/POLISHED/selection-scheme-best.csv', header = TRUE, stringsAsFactors = FALSE)
ss_ssf <- read.csv('./DATA-FINAL/POLISHED/selection-scheme-ssf.csv', header = TRUE, stringsAsFactors = FALSE)

## genotypic fitness sharing data frames
gfs_ot <- filter(ss_over_time, acron == 'gfs')
gfs_ot$Sigma <- factor(gfs_ot$trt, levels = FS_LIST)
gfs_best <- filter(ss_best, acron == 'gfs')
gfs_best$Sigma <- factor(gfs_best$trt, levels = FS_LIST)
gfs_end  <- filter(gfs_ot, gen == 50000)

## phenotypic fitness sharing data frames
pfs_ot <- filter(ss_over_time, acron == 'pfs')
pfs_ot$Sigma <- factor(pfs_ot$trt, levels = FS_LIST)
pfs_best <- filter(ss_best, acron == 'pfs')
pfs_best$Sigma <- factor(pfs_best$trt, levels = FS_LIST)
pfs_end  <- filter(pfs_ot, gen == 50000)

## nodominated sorting data frames
nds_ot <- filter(ss_over_time, acron == 'nds')
nds_ot$Sigma <- factor(nds_ot$trt, levels = ND_LIST)
nds_best <- filter(ss_best, acron == 'nds')
nds_best$Sigma <- factor(nds_best$trt, levels = ND_LIST)
nds_end  <- filter(nds_ot, gen == 50000)

## novelty search data frames
nov_ot <- filter(ss_over_time, acron == 'nov' & trt != 0)
nov_ot$K <- factor(nov_ot$trt, levels = NS_LIST)
nov_best <- filter(ss_best, acron == 'nov' & trt != 0)
nov_best$K <- factor(nov_best$trt, levels = NS_LIST)
nov_end  <- filter(nov_ot, gen == 50000)

## tournament data frames
tor_ot <- filter(ss_over_time, acron == 'tor' & trt != 1)
tor_ot$T <- factor(tor_ot$trt, levels = TS_LIST)
tor_best <- filter(ss_best, acron == 'tor' & trt != 1)
tor_best$T <- factor(tor_best$trt, levels = TS_LIST)
tor_end  <- filter(tor_ot, gen == 50000)
tor_ssf <- filter(ss_ssf, acron == 'tor' & trt != 1)
tor_ssf$T <- factor(tor_ssf$trt, levels = TS_LIST)
tor_ssf[is.na(tor_ssf)] <- 59999

## truncation data frames
tru_ot <- filter(ss_over_time, acron == 'tru')
tru_ot$T <- factor(tru_ot$trt, levels = TR_LIST)
tru_best <- filter(ss_best, acron == 'tru')
tru_best$T <- factor(tru_best$trt, levels = TR_LIST)
tru_end  <- filter(tru_ot, gen == 50000)
tru_ssf <- filter(ss_ssf, acron == 'tru')
tru_ssf$T <- factor(tru_ssf$trt, levels = TR_LIST)
tru_ssf[is.na(tru_ssf)] <- 59999
```

These analyses were conducted in the following computing environment:

```{r version}
print(version)
```