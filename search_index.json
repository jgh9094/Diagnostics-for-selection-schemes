[["index.html", "Diagnostics Supplemental Material Chapter 1 Introduction 1.1 About our supplemental material 1.2 Contributing authors 1.3 Research overview 1.4 Computer Setup 1.5 Experimental setup", " Diagnostics Supplemental Material Jose Guadalupe Hernandez 2023-01-30 Chapter 1 Introduction This is the supplemental material associated with our 2022 ECJ contribution entitled, A suite of diagnostic metrics for characterizing selection schemes. Preprint here. 1.1 About our supplemental material This supplemental material is hosted on GitHub using GitHub pages. The source code and configuration files used to generate this supplemental material can be found in this GitHub repository. We compiled our data analyses and supplemental documentation into this nifty web-accessible book using bookdown. Our supplemental material includes the following paper figures and statistics: Exploitation rate results (Section 2) Ordered exploitation results (Section ??) Contradictory objectives results (Section ??) Multi-path exploration results (Section ??) Multi-valley crossing results (Section 2.5) Additionally, our supplemental material includes the results from parameter tuning selection schemes: Truncation selection (Section ??) Tournament selection sharing (Section ??) Genotypic fitness sharing (Section ??) Phenotypic fitness sharing (Section ??) Nondominated sorting (Section ??) Novelty search (Section ??) 1.2 Contributing authors Jose Guadalupe Hernandez Alexander Lalejini Charles Ofria 1.3 Research overview Abstract: Evolutionary algorithms typically consist of multiple interacting components, where each component influences an algorithms problem-solving abilities. Understanding how each component of an evolutionary algorithm influences problem-solving success can improve our ability to target particular problem domains. Benchmark suites provide insights into an evolutionary algorithms problem-solving capabilities, but benchmarking problems often have complex search space topologies, making it difficult to isolate and test an algorithms strengths and weaknesses. Our work focuses on diagnosing selection schemes, which identify individuals to contribute genetic material to the next generation, thus driving an evolutionary algorithms search strategy. We introduce four diagnostics for empirically testing the strengths and weaknesses of selection schemes: the exploitation rate diagnostic, ordered exploitation rate diagnostic, contradictory objectives diagnostic, and the multi-path exploration diagnostic. Each diagnostic is a handcrafted search space designed to isolate and measure the relative exploitation and exploration characteristics of selection schemes. Here, we use our diagnostics to evaluate six population selection methods: truncation selection, tournament selection, fitness sharing, lexicase selection, nondominated sorting, and novelty search. Expectedly, tournament and truncation selection excelled at gradient exploitation but poorly explored search spaces, while novelty search excelled at exploration but failed to exploit gradients. Fitness sharing performed poorly across all diagnostics, suggesting poor overall exploitation and exploration abilities. Nondominated sorting was best for maintaining diverse populations comprised of individuals inhabiting multiple optima, but struggled to effectively exploit gradients. Lexicase selection balanced search space exploration without sacrificing exploitation, generally performing well across diagnostics. Our work demonstrates the value of diagnostics for building a deeper understanding of selection schemes, which can then be used to improve or develop new selection methods. 1.4 Computer Setup These analyses were conducted in the following computing environment: print(version) ## _ ## platform x86_64-pc-linux-gnu ## arch x86_64 ## os linux-gnu ## system x86_64, linux-gnu ## status Patched ## major 4 ## minor 2.2 ## year 2022 ## month 11 ## day 10 ## svn rev 83330 ## language R ## version.string R version 4.2.2 Patched (2022-11-10 r83330) ## nickname Innocent and Trusting 1.5 Experimental setup Setting up required variables variables. # includes library(plyr) library(dplyr) ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:plyr&#39;: ## ## arrange, count, desc, failwith, id, mutate, rename, summarise, ## summarize ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union library(tidyverse) ## -- Attaching packages --------------------------------------- tidyverse 1.3.2 ## -- ## v ggplot2 3.4.0 v purrr 1.0.1 ## v tibble 3.1.8 v stringr 1.5.0 ## v tidyr 1.3.0 v forcats 1.0.0 ## v readr 2.1.3 ## -- Conflicts ------------------------------------------ tidyverse_conflicts() -- ## x dplyr::arrange() masks plyr::arrange() ## x purrr::compact() masks plyr::compact() ## x dplyr::count() masks plyr::count() ## x dplyr::desc() masks plyr::desc() ## x dplyr::failwith() masks plyr::failwith() ## x dplyr::filter() masks stats::filter() ## x dplyr::id() masks plyr::id() ## x dplyr::lag() masks stats::lag() ## x dplyr::mutate() masks plyr::mutate() ## x dplyr::rename() masks plyr::rename() ## x dplyr::summarise() masks plyr::summarise() ## x dplyr::summarize() masks plyr::summarize() # graph variables SHAPE = c(5,3,1,2,6,0,4,20,1) cb_palette &lt;- c(&#39;#332288&#39;,&#39;#88CCEE&#39;,&#39;#EE7733&#39;,&#39;#EE3377&#39;,&#39;#117733&#39;,&#39;#882255&#39;,&#39;#44AA99&#39;,&#39;#CCBB44&#39;, &#39;#000000&#39;) mvc_col = c(&#39;#1A85FF&#39;,&#39;#D41159&#39;) TSIZE = 26 p_theme &lt;- theme( text = element_text(size = 28), plot.title = element_text( face = &quot;bold&quot;, size = 22, hjust=0.5), panel.border = element_blank(), panel.grid.minor = element_blank(), legend.title=element_text(size=22), legend.text=element_text(size=23), axis.title = element_text(size=23), axis.text = element_text(size=22), legend.position=&quot;bottom&quot;, panel.background = element_rect(fill = &quot;#f1f2f5&quot;, colour = &quot;white&quot;, size = 0.5, linetype = &quot;solid&quot;) ) ## Warning: The `size` argument of `element_rect()` is deprecated as of ggplot2 3.4.0. ## i Please use the `linewidth` argument instead. # default variables REPLICATES = 50 DIMENSIONALITY = 100 # selection scheme related stuff ACRON = tolower(c(&#39;TRU&#39;,&#39;TOR&#39;,&#39;LEX&#39;,&#39;GFS&#39;,&#39;PFS&#39;,&#39;NDS&#39;,&#39;NOV&#39;,&#39;RAN&#39;)) NAMES = c(&#39;Truncation (tru)&#39;,&#39;Tournament (tor)&#39;,&#39;Lexicase (lex)&#39;, &#39;Genotypic Fitness Sharing (gfs)&#39;,&#39;Phenotypic Fitness Sharing (pfs)&#39;,&#39;Nondominated Sorting (nds)&#39;,&#39;Novelty Search (nov)&#39;,&#39;Random (ran)&#39;) SCHEME = c(&#39;TRUNCATION&#39;,&#39;TOURNAMENT&#39;,&#39;LEXICASE&#39;,&#39;FITSHARING_G&#39;,&#39;FITSHARING_P&#39;,&#39;NONDOMINATEDSORTING&#39;,&#39;NOVELTY&#39;,&#39;TOURNAMENT&#39;) ORDER = c(&#39;Truncation (tru)&#39;,&#39;Tournament (tor)&#39;,&#39;Lexicase (lex)&#39;, &#39;Genotypic Fitness Sharing (gfs)&#39;,&#39;Phenotypic Fitness Sharing (pfs)&#39;,&#39;Nondominated Sorting (nds)&#39;,&#39;Novelty Search (nov)&#39;,&#39;Random (ran)&#39;) # selection scheme parameters TR_LIST = c(1, 2, 4, 8, 16, 32, 64, 128, 256) TS_LIST = c(2, 4, 8, 16, 32, 64, 128, 256) FS_LIST = c(0.0, 0.1, 0.3, 0.6, 1.2, 2.5, 5.0) ND_LIST = c(0.0, 0.1, 0.3, 0.6, 1.2, 2.5, 5.0) NS_LIST = c(1, 2, 4, 8, 15, 30) # selection scheme parameter we are looking for PARAM = c(&#39;8&#39;, &#39;8&#39;, &#39;0.0&#39;, &#39;0.3&#39;, &#39;0.3&#39;, &#39;0.3&#39;, &#39;15&#39;, &#39;1&#39;) # for diagnostic loops DIAGNOSTIC = tolower(c(&#39;EXPLOITATION_RATE&#39;, &#39;ORDERED_EXPLOITATION&#39;, &#39;CONTRADICTORY_OBJECTIVES&#39;, &#39;MULTIPATH_EXPLORATION&#39;)) # data diractory for gh-pages DATA_DIR = &#39;/opt/ECJ-2022-suite-of-diagnostics-for-selection-schemes/DATA-FINAL/&#39; ###################################################################################### # go through each diagnostic and collect over time data for cross comparison (cc) print(&#39;Collecting over time data...&#39;) ## [1] &quot;Collecting over time data...&quot; cc_over_time = data.frame() cc_over_time_mvc = data.frame() for(diagnostic in DIAGNOSTIC) { print(paste(&#39;DIAGNOSTIC&#39;,diagnostic)) for(i in 1:8) { print(paste(&#39;SCHEME:&#39;,SCHEME[i])) dir = paste(DATA_DIR,&#39;NO-MVC/&#39;,SCHEME[i],&#39;/over-time-&#39;,diagnostic,&#39;-&#39;, tolower(SCHEME[i]), &#39;.csv&#39;, sep = &quot;&quot;, collapse = NULL) dir_mvc = paste(DATA_DIR,&#39;MVC/&#39;,SCHEME[i],&#39;/over-time-&#39;,diagnostic,&#39;-&#39;, tolower(SCHEME[i]), &#39;.csv&#39;, sep = &quot;&quot;, collapse = NULL) # read csv df = read.csv(dir, header = TRUE, stringsAsFactors = FALSE) df_mvc = read.csv(dir_mvc, header = TRUE, stringsAsFactors = FALSE) # add names/tags df$acron = ACRON[i] df$`Selection\\nScheme` = NAMES[i] df$diagnostic = diagnostic df_mvc$acron = ACRON[i] df_mvc$`Selection\\nScheme` = NAMES[i] df_mvc$diagnostic = diagnostic # add to cc_over_time data frame if(i == 3) { cc_over_time = rbind(cc_over_time, df) cc_over_time_mvc = rbind(cc_over_time_mvc, df_mvc) } else { cc_over_time = rbind(cc_over_time, filter(df, trt == PARAM[i])) cc_over_time_mvc = rbind(cc_over_time_mvc, filter(df_mvc, trt == PARAM[i])) } } rm(df); rm(df_mvc); rm(dir); rm(dir_mvc) } ## [1] &quot;DIAGNOSTIC exploitation_rate&quot; ## [1] &quot;SCHEME: TRUNCATION&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; ## [1] &quot;SCHEME: LEXICASE&quot; ## [1] &quot;SCHEME: FITSHARING_G&quot; ## [1] &quot;SCHEME: FITSHARING_P&quot; ## [1] &quot;SCHEME: NONDOMINATEDSORTING&quot; ## [1] &quot;SCHEME: NOVELTY&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; ## [1] &quot;DIAGNOSTIC ordered_exploitation&quot; ## [1] &quot;SCHEME: TRUNCATION&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; ## [1] &quot;SCHEME: LEXICASE&quot; ## [1] &quot;SCHEME: FITSHARING_G&quot; ## [1] &quot;SCHEME: FITSHARING_P&quot; ## [1] &quot;SCHEME: NONDOMINATEDSORTING&quot; ## [1] &quot;SCHEME: NOVELTY&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; ## [1] &quot;DIAGNOSTIC contradictory_objectives&quot; ## [1] &quot;SCHEME: TRUNCATION&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; ## [1] &quot;SCHEME: LEXICASE&quot; ## [1] &quot;SCHEME: FITSHARING_G&quot; ## [1] &quot;SCHEME: FITSHARING_P&quot; ## [1] &quot;SCHEME: NONDOMINATEDSORTING&quot; ## [1] &quot;SCHEME: NOVELTY&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; ## [1] &quot;DIAGNOSTIC multipath_exploration&quot; ## [1] &quot;SCHEME: TRUNCATION&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; ## [1] &quot;SCHEME: LEXICASE&quot; ## [1] &quot;SCHEME: FITSHARING_G&quot; ## [1] &quot;SCHEME: FITSHARING_P&quot; ## [1] &quot;SCHEME: NONDOMINATEDSORTING&quot; ## [1] &quot;SCHEME: NOVELTY&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; cc_over_time$`Selection\\nScheme` &lt;- factor(cc_over_time$`Selection\\nScheme`, levels = ORDER) cc_over_time$acron &lt;- factor(cc_over_time$acron, levels = ACRON) cc_over_time$uni_str_pos = cc_over_time$uni_str_pos + cc_over_time$arc_acti_gene - cc_over_time$overlap cc_over_time = subset(cc_over_time, select = -c(trt,pop_fit_avg,archive_cnt,pmin,pareto_cnt,arc_acti_gene,overlap)) cc_over_time_mvc$`Selection\\nScheme` &lt;- factor(cc_over_time$`Selection\\nScheme`, levels = ORDER) cc_over_time_mvc$acron &lt;- factor(cc_over_time$acron, levels = ACRON) cc_over_time_mvc$uni_str_pos = cc_over_time_mvc$uni_str_pos + cc_over_time_mvc$arc_acti_gene - cc_over_time_mvc$overlap cc_over_time_mvc = subset(cc_over_time_mvc, select = -c(trt,pop_fit_avg,archive_cnt,pmin,pareto_cnt,arc_acti_gene,overlap)) ###################################################################################### # go through each diagnostic and collect best over time for cross comparison (cc) cc_best = data.frame() cc_best_mvc = data.frame() for(diagnostic in DIAGNOSTIC) { print(paste(&#39;DIAGNOSTIC&#39;,diagnostic)) for(i in 1:8) { print(paste(&#39;SCHEME:&#39;,SCHEME[i])) dir = paste(DATA_DIR,&#39;NO-MVC/&#39;,SCHEME[i],&#39;/best-&#39;,diagnostic,&#39;-&#39;, tolower(SCHEME[i]), &#39;.csv&#39;, sep = &quot;&quot;, collapse = NULL) dir_mvc = paste(DATA_DIR,&#39;MVC/&#39;,SCHEME[i],&#39;/best-&#39;,diagnostic,&#39;-&#39;, tolower(SCHEME[i]), &#39;.csv&#39;, sep = &quot;&quot;, collapse = NULL) # read csv df = read.csv(dir, header = TRUE, stringsAsFactors = FALSE) df_mvc = read.csv(dir_mvc, header = TRUE, stringsAsFactors = FALSE) # add names/tags df$acron = ACRON[i] df$`Selection\\nScheme` = NAMES[i] df$diagnostic = diagnostic df = subset(df, select = -c(Diagnostic,SEL) ) df_mvc$acron = ACRON[i] df_mvc$`Selection\\nScheme` = NAMES[i] df_mvc$diagnostic = diagnostic df_mvc = subset(df_mvc, select = -c(Diagnostic,SEL) ) # add to cc_over_time data frame if(i == 3) { cc_best = rbind(cc_best, df) cc_best_mvc = rbind(cc_best_mvc, df_mvc) } else { cc_best = rbind(cc_best, filter(df, trt == PARAM[i])) cc_best_mvc = rbind(cc_best_mvc, filter(df_mvc, trt == PARAM[i])) } } rm(df); rm(df_mvc); rm(dir); rm(dir_mvc) } ## [1] &quot;DIAGNOSTIC exploitation_rate&quot; ## [1] &quot;SCHEME: TRUNCATION&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; ## [1] &quot;SCHEME: LEXICASE&quot; ## [1] &quot;SCHEME: FITSHARING_G&quot; ## [1] &quot;SCHEME: FITSHARING_P&quot; ## [1] &quot;SCHEME: NONDOMINATEDSORTING&quot; ## [1] &quot;SCHEME: NOVELTY&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; ## [1] &quot;DIAGNOSTIC ordered_exploitation&quot; ## [1] &quot;SCHEME: TRUNCATION&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; ## [1] &quot;SCHEME: LEXICASE&quot; ## [1] &quot;SCHEME: FITSHARING_G&quot; ## [1] &quot;SCHEME: FITSHARING_P&quot; ## [1] &quot;SCHEME: NONDOMINATEDSORTING&quot; ## [1] &quot;SCHEME: NOVELTY&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; ## [1] &quot;DIAGNOSTIC contradictory_objectives&quot; ## [1] &quot;SCHEME: TRUNCATION&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; ## [1] &quot;SCHEME: LEXICASE&quot; ## [1] &quot;SCHEME: FITSHARING_G&quot; ## [1] &quot;SCHEME: FITSHARING_P&quot; ## [1] &quot;SCHEME: NONDOMINATEDSORTING&quot; ## [1] &quot;SCHEME: NOVELTY&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; ## [1] &quot;DIAGNOSTIC multipath_exploration&quot; ## [1] &quot;SCHEME: TRUNCATION&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; ## [1] &quot;SCHEME: LEXICASE&quot; ## [1] &quot;SCHEME: FITSHARING_G&quot; ## [1] &quot;SCHEME: FITSHARING_P&quot; ## [1] &quot;SCHEME: NONDOMINATEDSORTING&quot; ## [1] &quot;SCHEME: NOVELTY&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; cc_best$acron &lt;- factor(cc_best$acron, levels = ACRON) cc_best = subset(cc_best, select = -c(trt,gen)) cc_best = filter(cc_best, col == &#39;pop_fit_max&#39; | col == &#39;pop_uni_obj&#39;) cc_best_mvc$acron &lt;- factor(cc_best_mvc$acron, levels = ACRON) cc_best_mvc = subset(cc_best_mvc, select = -c(trt,gen)) cc_best_mvc = subset(cc_best_mvc, col == &#39;pop_fit_max&#39; | col == &#39;pop_uni_obj&#39;) ###################################################################################### # get generation a satisfactory solution is found for cross comparison (cc) cc_ssf = data.frame() for(diagnostic in DIAGNOSTIC) { if(diagnostic == &#39;contradictory_objectives&#39; | diagnostic == &#39;multipath_exploration&#39;) {next} print(paste(&#39;DIAGNOSTIC&#39;,diagnostic)) for(i in 1:8) { print(paste(&#39;SCHEME:&#39;,SCHEME[i])) dir = paste(DATA_DIR,&#39;NO-MVC/&#39;,SCHEME[i],&#39;/ssf-&#39;,diagnostic,&#39;-&#39;, tolower(SCHEME[i]), &#39;.csv&#39;, sep = &quot;&quot;, collapse = NULL) # read csv df = read.csv(dir, header = TRUE, stringsAsFactors = FALSE) # add names/tags df$acron = ACRON[i] df$`Selection\\nScheme` = NAMES[i] df$diagnostic = diagnostic df = subset(df, select = -c(Diagnostic,SEL) ) # add to cc_over_time data frame if(i == 3) { cc_ssf = rbind(cc_ssf, df) } else { cc_ssf = rbind(cc_ssf, filter(df, trt == PARAM[i])) } } rm(df); rm(dir); } ## [1] &quot;DIAGNOSTIC exploitation_rate&quot; ## [1] &quot;SCHEME: TRUNCATION&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; ## [1] &quot;SCHEME: LEXICASE&quot; ## [1] &quot;SCHEME: FITSHARING_G&quot; ## [1] &quot;SCHEME: FITSHARING_P&quot; ## [1] &quot;SCHEME: NONDOMINATEDSORTING&quot; ## [1] &quot;SCHEME: NOVELTY&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; ## [1] &quot;DIAGNOSTIC ordered_exploitation&quot; ## [1] &quot;SCHEME: TRUNCATION&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; ## [1] &quot;SCHEME: LEXICASE&quot; ## [1] &quot;SCHEME: FITSHARING_G&quot; ## [1] &quot;SCHEME: FITSHARING_P&quot; ## [1] &quot;SCHEME: NONDOMINATEDSORTING&quot; ## [1] &quot;SCHEME: NOVELTY&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; cc_ssf$acron &lt;- factor(cc_ssf$acron, levels = ACRON) cc_ssf = subset(cc_ssf, select = -c(trt)) ###################################################################################### # go through each scheme and collect over time data ss_over_time = data.frame() ss_over_time_mvc = data.frame() for(i in 1:8) { # add to cc_over_time data frame if(i == 3 | i == 8) { next } print(SCHEME[i]) for(diagnostic in DIAGNOSTIC) { dir = paste(DATA_DIR,&#39;NO-MVC/&#39;,SCHEME[i],&#39;/over-time-&#39;,diagnostic,&#39;-&#39;, tolower(SCHEME[i]), &#39;.csv&#39;, sep = &quot;&quot;, collapse = NULL) dir_mvc = paste(DATA_DIR,&#39;MVC/&#39;,SCHEME[i],&#39;/over-time-&#39;,diagnostic,&#39;-&#39;, tolower(SCHEME[i]), &#39;.csv&#39;, sep = &quot;&quot;, collapse = NULL) # read csv df = read.csv(dir, header = TRUE, stringsAsFactors = FALSE) df_mvc = read.csv(dir_mvc, header = TRUE, stringsAsFactors = FALSE) # add names/tags df$acron = ACRON[i] df$diagnostic = diagnostic df_mvc$acron = ACRON[i] df_mvc$diagnostic = diagnostic ss_over_time = rbind(ss_over_time, df) ss_over_time_mvc = rbind(ss_over_time_mvc,df_mvc) } rm(df); rm(df_mvc); rm(dir); rm(dir_mvc) } ## [1] &quot;TRUNCATION&quot; ## [1] &quot;TOURNAMENT&quot; ## [1] &quot;FITSHARING_G&quot; ## [1] &quot;FITSHARING_P&quot; ## [1] &quot;NONDOMINATEDSORTING&quot; ## [1] &quot;NOVELTY&quot; # remove unused data ss_over_time$uni_str_pos = ss_over_time$uni_str_pos + ss_over_time$arc_acti_gene - ss_over_time$overlap ss_over_time = subset(ss_over_time, select = -c(pop_fit_avg,archive_cnt,pmin,pareto_cnt,arc_acti_gene,overlap)) ss_over_time_mvc$uni_str_pos = ss_over_time_mvc$uni_str_pos + ss_over_time_mvc$arc_acti_gene - ss_over_time_mvc$overlap ss_over_time_mvc = subset(ss_over_time_mvc, select = -c(pop_fit_avg,archive_cnt,pmin,pareto_cnt,arc_acti_gene,overlap)) ## tournament data frames tor_ot &lt;- data.frame() tor_ot &lt;- filter(ss_over_time, acron == &#39;tor&#39; &amp; trt != 1) tor_ot$T &lt;- factor(tor_ot$trt, levels = TS_LIST) tor_ot &lt;- subset(tor_ot, select = -c(acron,trt)) ## truncation data frames tru_ot &lt;- data.frame() tru_ot &lt;- filter(ss_over_time, acron == &#39;tru&#39;) tru_ot$T &lt;- factor(tru_ot$trt, levels = TR_LIST) tru_ot &lt;- subset(tru_ot, select = -c(acron,trt)) ## genotypic fitness sharing data frames gfs_ot &lt;- data.frame() gfs_ot &lt;- filter(ss_over_time, acron == &#39;gfs&#39;) gfs_ot$Sigma &lt;- factor(gfs_ot$trt, levels = FS_LIST) gfs_ot &lt;- subset(gfs_ot, select = -c(acron,trt)) ## phenotypic fitness sharing data frames pfs_ot &lt;- data.frame() pfs_ot &lt;- filter(ss_over_time, acron == &#39;pfs&#39;) pfs_ot$Sigma &lt;- factor(pfs_ot$trt, levels = FS_LIST) pfs_ot &lt;- subset(pfs_ot, select = -c(acron,trt)) ## nodominated sorting data frames nds_ot &lt;- data.frame() nds_ot &lt;- filter(ss_over_time, acron == &#39;nds&#39;) nds_ot$Sigma &lt;- factor(nds_ot$trt, levels = ND_LIST) nds_ot &lt;- subset(nds_ot, select = -c(acron,trt)) ## novelty search data frames nov_ot &lt;- data.frame() nov_ot &lt;- filter(ss_over_time, acron == &#39;nov&#39; &amp; trt != 0) nov_ot$K &lt;- factor(nov_ot$trt, levels = NS_LIST) nov_ot &lt;- subset(nov_ot, select = -c(acron,trt)) ## tournament data frames mvc tor_ot_mvc &lt;- data.frame() tor_ot_mvc &lt;- filter(ss_over_time_mvc, acron == &#39;tor&#39; &amp; trt != 1) tor_ot_mvc$T &lt;- factor(tor_ot_mvc$trt, levels = TS_LIST) tor_ot_mvc &lt;- subset(tor_ot_mvc, select = -c(acron,trt)) ## truncation data frames mvc tru_ot_mvc &lt;- data.frame() tru_ot_mvc &lt;- filter(ss_over_time_mvc, acron == &#39;tru&#39;) tru_ot_mvc$T &lt;- factor(tru_ot_mvc$trt, levels = TR_LIST) tru_ot_mvc &lt;- subset(tru_ot_mvc, select = -c(acron,trt)) ## genotypic fitness sharing data frames mvc gfs_ot_mvc &lt;- data.frame() gfs_ot_mvc &lt;- filter(ss_over_time_mvc, acron == &#39;gfs&#39;) gfs_ot_mvc$Sigma &lt;- factor(gfs_ot_mvc$trt, levels = FS_LIST) gfs_ot_mvc &lt;- subset(gfs_ot_mvc, select = -c(acron,trt)) ## phenotypic fitness sharing data frames mvc pfs_ot_mvc &lt;- data.frame() pfs_ot_mvc &lt;- filter(ss_over_time_mvc, acron == &#39;pfs&#39;) pfs_ot_mvc$Sigma &lt;- factor(pfs_ot_mvc$trt, levels = FS_LIST) pfs_ot_mvc &lt;- subset(pfs_ot_mvc, select = -c(acron,trt)) ## nodominated sorting data frames mvc nds_ot_mvc &lt;- data.frame() nds_ot_mvc &lt;- filter(ss_over_time_mvc, acron == &#39;nds&#39;) nds_ot_mvc$Sigma &lt;- factor(nds_ot_mvc$trt, levels = ND_LIST) nds_ot_mvc &lt;- subset(nds_ot_mvc, select = -c(acron,trt)) ## novelty search data frames mvc nov_ot_mvc &lt;- data.frame() nov_ot_mvc &lt;- filter(ss_over_time_mvc, acron == &#39;nov&#39; &amp; trt != 0) nov_ot_mvc$K &lt;- factor(nov_ot_mvc$trt, levels = NS_LIST) nov_ot_mvc &lt;- subset(nov_ot_mvc, select = -c(acron,trt)) # clean up rm(ss_over_time_mvc) rm(ss_over_time) ###################################################################################### # go through each scheme and collect best data ss_best = data.frame() ss_best_mvc = data.frame() for(i in 1:8) { # add to cc_best data frame if(i == 3 | i == 8) { next } print(SCHEME[i]) for(diagnostic in DIAGNOSTIC) { dir = paste(DATA_DIR,&#39;NO-MVC/&#39;,SCHEME[i],&#39;/best-&#39;,diagnostic,&#39;-&#39;, tolower(SCHEME[i]), &#39;.csv&#39;, sep = &quot;&quot;, collapse = NULL) dir_mvc = paste(DATA_DIR,&#39;MVC/&#39;,SCHEME[i],&#39;/best-&#39;,diagnostic,&#39;-&#39;, tolower(SCHEME[i]), &#39;.csv&#39;, sep = &quot;&quot;, collapse = NULL) # read csv df = read.csv(dir, header = TRUE, stringsAsFactors = FALSE) df_mvc = read.csv(dir_mvc, header = TRUE, stringsAsFactors = FALSE) # add names/tags df$acron = ACRON[i] df$diagnostic = diagnostic df_mvc$acron = ACRON[i] df_mvc$diagnostic = diagnostic ss_best = rbind(ss_best, df) ss_best_mvc = rbind(ss_best_mvc,df_mvc) } rm(df); rm(df_mvc); rm(dir); rm(dir_mvc) } ## [1] &quot;TRUNCATION&quot; ## [1] &quot;TOURNAMENT&quot; ## [1] &quot;FITSHARING_G&quot; ## [1] &quot;FITSHARING_P&quot; ## [1] &quot;NONDOMINATEDSORTING&quot; ## [1] &quot;NOVELTY&quot; # removed unused data ss_best = subset(ss_best, select = -c(gen)) ss_best = filter(ss_best, col == &#39;pop_fit_max&#39; | col == &#39;pop_uni_obj&#39;) ss_best_mvc = subset(ss_best_mvc, select = -c(gen)) ss_best_mvc = filter(ss_best_mvc, col == &#39;pop_fit_max&#39; | col == &#39;pop_uni_obj&#39;) ## tournament data frames tor_best &lt;- data.frame() tor_best &lt;- filter(ss_best, acron == &#39;tor&#39; &amp; trt != 1) tor_best$T &lt;- factor(tor_best$trt, levels = TS_LIST) tor_best &lt;- subset(tor_best, select = -c(acron,trt)) ## truncation data frames tru_best &lt;- data.frame() tru_best &lt;- filter(ss_best, acron == &#39;tru&#39;) tru_best$T &lt;- factor(tru_best$trt, levels = TR_LIST) tru_best &lt;- subset(tru_best, select = -c(acron,trt)) ## genotypic fitness sharing data frames gfs_best &lt;- data.frame() gfs_best &lt;- filter(ss_best, acron == &#39;gfs&#39;) gfs_best$Sigma &lt;- factor(gfs_best$trt, levels = FS_LIST) gfs_best &lt;- subset(gfs_best, select = -c(acron,trt)) ## phenotypic fitness sharing data frames pfs_best &lt;- data.frame() pfs_best &lt;- filter(ss_best, acron == &#39;pfs&#39;) pfs_best$Sigma &lt;- factor(pfs_best$trt, levels = FS_LIST) pfs_best &lt;- subset(pfs_best, select = -c(acron,trt)) ## nodominated sorting data frames nds_best &lt;- data.frame() nds_best &lt;- filter(ss_best, acron == &#39;nds&#39;) nds_best$Sigma &lt;- factor(nds_best$trt, levels = ND_LIST) nds_best &lt;- subset(nds_best, select = -c(acron,trt)) ## novelty search data frames nov_best &lt;- data.frame() nov_best &lt;- filter(ss_best, acron == &#39;nov&#39; &amp; trt != 0) nov_best$K &lt;- factor(nov_best$trt, levels = NS_LIST) nov_best &lt;- subset(nov_best, select = -c(acron,trt)) ## tournament data frames mvc tor_best_mvc &lt;- data.frame() tor_best_mvc &lt;- filter(ss_best_mvc, acron == &#39;tor&#39; &amp; trt != 1) tor_best_mvc$T &lt;- factor(tor_best_mvc$trt, levels = TS_LIST) tor_best_mvc &lt;- subset(tor_best_mvc, select = -c(acron,trt)) ## truncation data frames mvc tru_best_mvc &lt;- data.frame() tru_best_mvc &lt;- filter(ss_best_mvc, acron == &#39;tru&#39;) tru_best_mvc$T &lt;- factor(tru_best_mvc$trt, levels = TR_LIST) tru_best_mvc &lt;- subset(tru_best_mvc, select = -c(acron,trt)) ## genotypic fitness sharing data frames mvc gfs_best_mvc &lt;- data.frame() gfs_best_mvc &lt;- filter(ss_best_mvc, acron == &#39;gfs&#39;) gfs_best_mvc$Sigma &lt;- factor(gfs_best_mvc$trt, levels = FS_LIST) gfs_best_mvc &lt;- subset(gfs_best_mvc, select = -c(acron,trt)) ## phenotypic fitness sharing data frames mvc pfs_best_mvc &lt;- data.frame() pfs_best_mvc &lt;- filter(ss_best_mvc, acron == &#39;pfs&#39;) pfs_best_mvc$Sigma &lt;- factor(pfs_best_mvc$trt, levels = FS_LIST) pfs_best_mvc &lt;- subset(pfs_best_mvc, select = -c(acron,trt)) ## nodominated sorting data frames mvc nds_best_mvc &lt;- data.frame() nds_best_mvc &lt;- filter(ss_best_mvc, acron == &#39;nds&#39;) nds_best_mvc$Sigma &lt;- factor(nds_best_mvc$trt, levels = ND_LIST) nds_best_mvc &lt;- subset(nds_best_mvc, select = -c(acron,trt)) ## novelty search data frames mvc nov_best_mvc &lt;- data.frame() nov_best_mvc &lt;- filter(ss_best_mvc, acron == &#39;nov&#39; &amp; trt != 0) nov_best_mvc$K &lt;- factor(nov_best_mvc$trt, levels = NS_LIST) nov_best_mvc &lt;- subset(nov_best_mvc, select = -c(acron,trt)) # clean up rm(ss_best_mvc) rm(ss_best) ###################################################################################### # go through each scheme and collect satisfactory solution found #Tournament exp_dir = paste(DATA_DIR,&#39;NO-MVC/TOURNAMENT/ssf-exploitation_rate-tournament.csv&#39;, sep = &quot;&quot;, collapse = NULL) ord_dir = paste(DATA_DIR,&#39;NO-MVC/TOURNAMENT/ssf-ordered_exploitation-tournament.csv&#39;, sep = &quot;&quot;, collapse = NULL) # read csv exp_df = read.csv(exp_dir, header = TRUE, stringsAsFactors = FALSE) ord_df = read.csv(ord_dir, header = TRUE, stringsAsFactors = FALSE) # remove data exp_df = subset(exp_df, select = -c(SEL)) exp_df = filter(exp_df, trt != 1) ord_df = subset(ord_df, select = -c(SEL)) ord_df = filter(ord_df, trt != 1) # combine tru_ssf = rbind(exp_df,ord_df) #Truncation exp_dir = paste(DATA_DIR,&#39;NO-MVC/TRUNCATION/ssf-exploitation_rate-truncation.csv&#39;, sep = &quot;&quot;, collapse = NULL) ord_dir = paste(DATA_DIR,&#39;NO-MVC/TRUNCATION/ssf-ordered_exploitation-truncation.csv&#39;, sep = &quot;&quot;, collapse = NULL) # read csv exp_df = read.csv(exp_dir, header = TRUE, stringsAsFactors = FALSE) ord_df = read.csv(ord_dir, header = TRUE, stringsAsFactors = FALSE) # remove data exp_df = subset(exp_df, select = -c(SEL)) exp_df = filter(exp_df, trt != 1) ord_df = subset(ord_df, select = -c(SEL)) ord_df = filter(ord_df, trt != 1) # combine tru_ssf = rbind(exp_df,ord_df) #final clean up rm(i,exp_dir,ord_dir,exp_df,ord_df) "],["exploitation-rate-results.html", "Chapter 2 Exploitation rate results 2.1 Analysis dependencies 2.2 Performance over time 2.3 Best performance throughout 2.4 Generation satisfactory solution found 2.5 Multi-valley crossing results", " Chapter 2 Exploitation rate results Here we present the results for best performances found by each selection scheme replicate on the exploitation rate diagnostic. Best performance found refers to the largest average trait score found in a given population. Note that performance values fall between 0.0 and 100.0. 2.1 Analysis dependencies library(ggplot2) library(cowplot) library(dplyr) library(PupillometryR) library(sdamr) 2.2 Performance over time Best performance in a population over time. # data for lines and shading on plots lines = filter(cc_over_time, diagnostic == &#39;exploitation_rate&#39;) %&gt;% group_by(`Selection\\nScheme`, gen) %&gt;% dplyr::summarise( min = min(pop_fit_max) / DIMENSIONALITY, mean = mean(pop_fit_max) / DIMENSIONALITY, max = max(pop_fit_max) / DIMENSIONALITY ) ## `summarise()` has grouped output by &#39;Selection Scheme&#39;. You can override using ## the `.groups` argument. ggplot(lines, aes(x=gen, y=mean, group = `Selection\\nScheme`, fill =`Selection\\nScheme`, color = `Selection\\nScheme`, shape = `Selection\\nScheme`)) + geom_ribbon(aes(ymin = min, ymax = max), alpha = 0.1) + geom_line(size = 0.5) + geom_point(data = filter(lines, gen %% 2000 == 0 &amp; gen != 0), size = 1.5, stroke = 2.0, alpha = 1.0) + scale_y_continuous( name=&quot;Average trait score&quot;, limits=c(0, 100), breaks=seq(0,100, 20), labels=c(&quot;0&quot;, &quot;20&quot;, &quot;40&quot;, &quot;60&quot;, &quot;80&quot;, &quot;100&quot;) ) + scale_x_continuous( name=&quot;Generations&quot;, limits=c(0, 50000), breaks=c(0, 10000, 20000, 30000, 40000, 50000), labels=c(&quot;0e+4&quot;, &quot;1e+4&quot;, &quot;2e+4&quot;, &quot;3e+4&quot;, &quot;4e+4&quot;, &quot;5e+4&quot;) ) + scale_shape_manual(values=SHAPE)+ scale_colour_manual(values = cb_palette) + scale_fill_manual(values = cb_palette) + ggtitle(&#39;Performance over time&#39;)+ p_theme + theme(legend.title=element_blank()) + guides( shape=guide_legend(ncol=2, title.position = &quot;bottom&quot;), color=guide_legend(ncol=2, title.position = &quot;bottom&quot;), fill=guide_legend(ncol=2, title.position = &quot;bottom&quot;) ) 2.3 Best performance throughout Best performance found throughout 50,000 generations. ### best performance throughout filter(cc_best, col == &#39;pop_fit_max&#39; &amp; diagnostic == &#39;exploitation_rate&#39;) %&gt;% ggplot(., aes(x = acron, y = val / DIMENSIONALITY, color = acron, fill = acron, shape = acron)) + geom_flat_violin(position = position_nudge(x = .2, y = 0), scale = &#39;width&#39;, alpha = 0.2) + geom_point(position = position_jitter(width = .1), size = 1.5, alpha = 1.0) + geom_boxplot(color = &#39;black&#39;, width = .2, outlier.shape = NA, alpha = 0.0) + scale_y_continuous( name=&quot;Average trait score&quot;, limits=c(-1, 101), breaks=seq(0,100, 20), labels=c(&quot;0&quot;, &quot;20&quot;, &quot;40&quot;, &quot;60&quot;, &quot;80&quot;, &quot;100&quot;) ) + scale_x_discrete( name=&quot;Scheme&quot; )+ scale_shape_manual(values=SHAPE)+ scale_colour_manual(values = cb_palette, ) + scale_fill_manual(values = cb_palette) + ggtitle(&#39;Best performance throughout&#39;)+ p_theme + theme(legend.title=element_blank()) + guides( shape=guide_legend(nrow=2, title.position = &quot;bottom&quot;), color=guide_legend(nrow=2, title.position = &quot;bottom&quot;), fill=guide_legend(nrow=2, title.position = &quot;bottom&quot;) ) ## Warning: Using the `size` aesthietic with geom_polygon was deprecated in ggplot2 3.4.0. ## i Please use the `linewidth` aesthetic instead. 2.3.1 Stats Summary statistics for the best performance. #get data &amp; summarize performance = filter(cc_best, col == &#39;pop_fit_max&#39; &amp; diagnostic == &#39;exploitation_rate&#39;) performance$acron = factor(performance$acron, levels = c(&#39;tru&#39;, &#39;tor&#39;, &#39;lex&#39;, &#39;gfs&#39;, &#39;pfs&#39;, &#39;nov&#39;, &#39;nds&#39;, &#39;ran&#39;)) performance %&gt;% group_by(acron) %&gt;% dplyr::summarise( count = n(), na_cnt = sum(is.na(val)), min = min(val / DIMENSIONALITY, na.rm = TRUE), median = median(val / DIMENSIONALITY, na.rm = TRUE), mean = mean(val / DIMENSIONALITY, na.rm = TRUE), max = max(val / DIMENSIONALITY, na.rm = TRUE), IQR = IQR(val / DIMENSIONALITY, na.rm = TRUE) ) ## # A tibble: 8 x 8 ## acron count na_cnt min median mean max IQR ## &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 tru 50 0 100 100 100 100 0 ## 2 tor 50 0 100 100 100 100 0 ## 3 lex 50 0 99.9 99.9 99.9 99.9 0.0137 ## 4 gfs 50 0 57.7 59.3 59.4 60.8 1.31 ## 5 pfs 50 0 58.0 59.5 59.5 61.4 0.908 ## 6 nov 50 0 15.9 19.2 19.3 22.3 1.34 ## 7 nds 50 0 17.9 18.4 18.5 19.5 0.516 ## 8 ran 50 0 13.5 15.9 15.9 18.7 1.15 KruskalWallis test provides evidence of statistical differences. kruskal.test(val ~ acron, data = performance) ## ## Kruskal-Wallis rank sum test ## ## data: val by acron ## Kruskal-Wallis chi-squared = 384.91, df = 7, p-value &lt; 2.2e-16 Results for post-hoc Wilcoxon rank-sum test with a Bonferroni correction. pairwise.wilcox.test(x = performance$val, g = performance$acron, p.adjust.method = &quot;bonferroni&quot;, paired = FALSE, conf.int = FALSE, alternative = &#39;l&#39;) ## ## Pairwise comparisons using Wilcoxon rank sum test with continuity correction ## ## data: performance$val and performance$acron ## ## tru tor lex gfs pfs nov nds ## tor 1e+00 - - - - - - ## lex &lt; 2e-16 &lt; 2e-16 - - - - - ## gfs &lt; 2e-16 &lt; 2e-16 &lt; 2e-16 - - - - ## pfs &lt; 2e-16 &lt; 2e-16 &lt; 2e-16 1e+00 - - - ## nov &lt; 2e-16 &lt; 2e-16 &lt; 2e-16 &lt; 2e-16 &lt; 2e-16 - - ## nds &lt; 2e-16 &lt; 2e-16 &lt; 2e-16 &lt; 2e-16 &lt; 2e-16 6e-04 - ## ran &lt; 2e-16 &lt; 2e-16 &lt; 2e-16 &lt; 2e-16 &lt; 2e-16 1.9e-15 7.9e-16 ## ## P value adjustment method: bonferroni 2.4 Generation satisfactory solution found First generation a satisfactory solution is found throughout the 50,000 generations. filter(cc_ssf, diagnostic == &#39;exploitation_rate&#39;) %&gt;% ggplot(., aes(x = acron, y = Generations , color = acron, fill = acron, shape = acron)) + geom_flat_violin(position = position_nudge(x = .2, y = 0), scale = &#39;width&#39;, alpha = 0.2) + geom_point(position = position_jitter(width = .1), size = 1.5, alpha = 1.0) + geom_boxplot(color = &#39;black&#39;, width = .2, outlier.shape = NA, alpha = 0.0) + scale_y_continuous( name=&quot;Generation&quot;, limits=c(0, 60001), breaks=c(0, 10000, 20000, 30000, 40000, 50000, 60000), labels=c(&quot;0e+4&quot;, &quot;1e+4&quot;, &quot;2e+4&quot;, &quot;3e+4&quot;, &quot;4e+4&quot;, &quot;5e+4&quot;, &quot;Fail&quot;) ) + scale_x_discrete( name=&quot;Scheme&quot; )+ scale_shape_manual(values=SHAPE)+ scale_colour_manual(values = cb_palette, ) + scale_fill_manual(values = cb_palette) + ggtitle(&#39;Generation satisfactory solution found&#39;)+ p_theme + theme(legend.title=element_blank()) + guides( shape=guide_legend(nrow=2, title.position = &quot;bottom&quot;), color=guide_legend(nrow=2, title.position = &quot;bottom&quot;), fill=guide_legend(nrow=2, title.position = &quot;bottom&quot;) ) 2.4.1 Stats Summary statistics for the first generation a satisfactory solution is found. ssf = filter(cc_ssf, diagnostic == &#39;exploitation_rate&#39; &amp; Generations &lt; 60000) ssf$acron = factor(ssf$acron, levels = c(&#39;tru&#39;, &#39;tor&#39;, &#39;lex&#39;)) ssf %&gt;% group_by(acron) %&gt;% dplyr::summarise( count = n(), na_cnt = sum(is.na(Generations)), min = min(Generations, na.rm = TRUE), median = median(Generations, na.rm = TRUE), mean = mean(Generations, na.rm = TRUE), max = max(Generations, na.rm = TRUE), IQR = IQR(Generations, na.rm = TRUE) ) ## # A tibble: 3 x 8 ## acron count na_cnt min median mean max IQR ## &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 tru 50 0 3357 3420 3421. 3481 34.2 ## 2 tor 50 0 5403 5457 5453. 5519 51.8 ## 3 lex 50 0 23514 25190 25857. 32980 1581 KruskalWallis test provides evidence of difference amoung selection schemes. kruskal.test(Generations ~ acron, data = ssf) ## ## Kruskal-Wallis rank sum test ## ## data: Generations by acron ## Kruskal-Wallis chi-squared = 132.46, df = 2, p-value &lt; 2.2e-16 Results for post-hoc Wilcoxon rank-sum test with a Bonferroni correction. pairwise.wilcox.test(x = ssf$Generations, g = ssf$acron, p.adjust.method = &quot;bonferroni&quot;, paired = FALSE, conf.int = FALSE, alternative = &#39;g&#39;) ## ## Pairwise comparisons using Wilcoxon rank sum test with continuity correction ## ## data: ssf$Generations and ssf$acron ## ## tru tor ## tor &lt;2e-16 - ## lex &lt;2e-16 &lt;2e-16 ## ## P value adjustment method: bonferroni 2.5 Multi-valley crossing results 2.5.1 Performance over time Best performance in a population over time. # data for lines and shading on plots lines = filter(cc_over_time_mvc, diagnostic == &#39;exploitation_rate&#39;) %&gt;% group_by(`Selection\\nScheme`, gen) %&gt;% dplyr::summarise( min = min(pop_fit_max) / DIMENSIONALITY, mean = mean(pop_fit_max) / DIMENSIONALITY, max = max(pop_fit_max) / DIMENSIONALITY ) ## `summarise()` has grouped output by &#39;Selection Scheme&#39;. You can override using ## the `.groups` argument. ggplot(lines, aes(x=gen, y=mean, group = `Selection\\nScheme`, fill =`Selection\\nScheme`, color = `Selection\\nScheme`, shape = `Selection\\nScheme`)) + geom_ribbon(aes(ymin = min, ymax = max), alpha = 0.1) + geom_line(size = 0.5) + geom_point(data = filter(lines, gen %% 2000 == 0 &amp; gen != 0), size = 1.5, stroke = 2.0, alpha = 1.0) + scale_y_continuous( name=&quot;Average trait score&quot;, limits=c(0, 50), breaks=seq(0,50, 10), labels=c(&quot;0&quot;, &quot;10&quot;, &quot;20&quot;, &quot;30&quot;, &quot;40&quot;, &quot;50&quot;) ) + scale_x_continuous( name=&quot;Generations&quot;, limits=c(0, 50000), breaks=c(0, 10000, 20000, 30000, 40000, 50000), labels=c(&quot;0e+4&quot;, &quot;1e+4&quot;, &quot;2e+4&quot;, &quot;3e+4&quot;, &quot;4e+4&quot;, &quot;5e+4&quot;) ) + scale_shape_manual(values=SHAPE)+ scale_colour_manual(values = cb_palette) + scale_fill_manual(values = cb_palette) + ggtitle(&#39;Performance over time&#39;)+ p_theme + guides( sh=guide_legend(ncol=2, title.position = &quot;left&quot;), color=guide_legend(ncol=2, title.position = &quot;left&quot;), fillape=guide_legend(ncol=2, title.position = &quot;left&quot;) ) 2.5.2 Best performance throughout Best performance found throughout 50,000 generations. ### best performance throughout filter(cc_best_mvc, col == &#39;pop_fit_max&#39; &amp; diagnostic == &#39;exploitation_rate&#39;) %&gt;% ggplot(., aes(x = acron, y = val / DIMENSIONALITY, color = acron, fill = acron, shape = acron)) + geom_flat_violin(position = position_nudge(x = .2, y = 0), scale = &#39;width&#39;, alpha = 0.2) + geom_point(position = position_jitter(width = .1), size = 1.5, alpha = 1.0) + geom_boxplot(color = &#39;black&#39;, width = .2, outlier.shape = NA, alpha = 0.0) + scale_y_continuous( name=&quot;Average trait score&quot;, limits=c(0, 50), breaks=seq(0,50, 10), labels=c(&quot;0&quot;, &quot;10&quot;, &quot;20&quot;, &quot;30&quot;, &quot;40&quot;, &quot;50&quot;) ) + scale_x_discrete( name=&quot;Scheme&quot; )+ scale_shape_manual(values=SHAPE)+ scale_colour_manual(values = cb_palette, ) + scale_fill_manual(values = cb_palette) + ggtitle(&#39;Best performance throughout&#39;)+ p_theme + theme(legend.title=element_blank()) + guides( shape=guide_legend(nrow=2, title.position = &quot;bottom&quot;), color=guide_legend(nrow=2, title.position = &quot;bottom&quot;), fill=guide_legend(nrow=2, title.position = &quot;bottom&quot;) ) 2.5.2.1 Stats Summary statistics for the performance of the best performance. #get data &amp; summarize performance = filter(cc_best_mvc, col == &#39;pop_fit_max&#39; &amp; diagnostic == &#39;exploitation_rate&#39;) performance$acron = factor(performance$acron, levels = c(&#39;gfs&#39;,&#39;pfs&#39;,&#39;tru&#39;,&#39;tor&#39;,&#39;nov&#39;, &#39;nds&#39;,&#39;lex&#39;, &#39;ran&#39;)) performance %&gt;% group_by(acron) %&gt;% dplyr::summarise( count = n(), na_cnt = sum(is.na(val)), min = min(val / DIMENSIONALITY, na.rm = TRUE), median = median(val / DIMENSIONALITY, na.rm = TRUE), mean = mean(val / DIMENSIONALITY, na.rm = TRUE), max = max(val / DIMENSIONALITY, na.rm = TRUE), IQR = IQR(val / DIMENSIONALITY, na.rm = TRUE) ) ## # A tibble: 8 x 8 ## acron count na_cnt min median mean max IQR ## &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 gfs 50 0 40.8 43.0 43.0 45.8 1.12 ## 2 pfs 50 0 40.9 43.1 43.1 45.3 1.30 ## 3 tru 50 0 17.8 18.0 18.0 18.2 0.118 ## 4 tor 50 0 17.9 18.1 18.1 18.3 0.130 ## 5 nov 50 0 16.5 18.3 18.3 21.5 1.19 ## 6 nds 50 0 14.7 15.4 15.3 16.0 0.318 ## 7 lex 50 0 12.5 12.7 12.7 13.1 0.121 ## 8 ran 50 0 10.3 13.2 13.1 14.6 1.25 KruskalWallis test provides evidence of statistical differences. kruskal.test(val ~ acron, data = performance) ## ## Kruskal-Wallis rank sum test ## ## data: val by acron ## Kruskal-Wallis chi-squared = 366.01, df = 7, p-value &lt; 2.2e-16 Results for post-hoc Wilcoxon rank-sum test with a Bonferroni correction. pairwise.wilcox.test(x = performance$val, g = performance$acron, p.adjust.method = &quot;bonferroni&quot;, paired = FALSE, conf.int = FALSE, alternative = &#39;l&#39;) ## ## Pairwise comparisons using Wilcoxon rank sum test with continuity correction ## ## data: performance$val and performance$acron ## ## gfs pfs tru tor nov nds lex ## pfs 1 - - - - - - ## tru &lt;2e-16 &lt;2e-16 - - - - - ## tor &lt;2e-16 &lt;2e-16 1 - - - - ## nov &lt;2e-16 &lt;2e-16 1 1 - - - ## nds &lt;2e-16 &lt;2e-16 &lt;2e-16 &lt;2e-16 &lt;2e-16 - - ## lex &lt;2e-16 &lt;2e-16 &lt;2e-16 &lt;2e-16 &lt;2e-16 &lt;2e-16 - ## ran &lt;2e-16 &lt;2e-16 &lt;2e-16 &lt;2e-16 &lt;2e-16 &lt;2e-16 1 ## ## P value adjustment method: bonferroni 2.5.3 Performance comparison Best performances in the population at 40,000 and 50,000 generations. ## Warning: The following aesthetics were dropped during statistical transformation: ## colour, shape ## i This can happen when ggplot fails to infer the correct grouping structure in ## the data. ## i Did you forget to specify a `group` aesthetic or to convert a numerical ## variable into a factor? ## The following aesthetics were dropped during statistical transformation: ## colour, shape ## i This can happen when ggplot fails to infer the correct grouping structure in ## the data. ## i Did you forget to specify a `group` aesthetic or to convert a numerical ## variable into a factor? # 80% and final generation comparison end = filter(cc_over_time_mvc, diagnostic == &#39;exploitation_rate&#39; &amp; gen == 50000 &amp; acron != &#39;ran&#39;) end$Generation &lt;- factor(end$gen) mid = filter(cc_over_time_mvc, diagnostic == &#39;exploitation_rate&#39; &amp; gen == 40000 &amp; acron != &#39;ran&#39;) mid$Generation &lt;- factor(mid$gen) mvc_p = ggplot(mid, aes(x = acron, y=pop_fit_max / DIMENSIONALITY, group = acron, shape = Generation)) + geom_point(col = mvc_col[1] , position = position_jitternudge(jitter.width = .03, nudge.x = -0.05), size = 2, alpha = 1.0) + geom_boxplot(position = position_nudge(x = -.15, y = 0), lwd = 0.7, col = mvc_col[1], fill = mvc_col[1], width = .1, outlier.shape = NA, alpha = 0.0) + geom_point(data = end, aes(x = acron, y=pop_fit_max / DIMENSIONALITY), col = mvc_col[2], position = position_jitternudge(jitter.width = .03, nudge.x = 0.05), size = 2, alpha = 1.0) + geom_boxplot(data = end, aes(x = acron, y=pop_fit_max / DIMENSIONALITY), position = position_nudge(x = .15, y = 0), lwd = 0.7, col = mvc_col[2], fill = mvc_col[2], width = .1, outlier.shape = NA, alpha = 0.0) + scale_y_continuous( name=&quot;Average trait score&quot;, limits=c(0, 50), breaks=seq(0,50, 10), labels=c(&quot;0&quot;, &quot;10&quot;, &quot;20&quot;, &quot;30&quot;, &quot;40&quot;, &quot;50&quot;) ) + scale_x_discrete( name=&quot;Scheme&quot; )+ scale_shape_manual(values=c(0,1))+ scale_colour_manual(values = c(mvc_col[1],mvc_col[2])) + p_theme plot_grid( mvc_p + ggtitle(&quot;Performance comparisons&quot;) + theme(legend.position=&quot;none&quot;), legend, nrow=2, rel_heights = c(1,.05), label_size = TSIZE ) 2.5.3.1 Stats Summary statistics for the performance of the best performance at 40,000 and 50,000 generations. ### performance comparisons and generation slices 40K &amp; 50K slices = filter(cc_over_time_mvc, diagnostic == &#39;exploitation_rate&#39; &amp; (gen == 50000 | gen == 40000) &amp; acron != &#39;ran&#39;) slices$Generation &lt;- factor(slices$gen, levels = c(50000,40000)) slices$acron = factor(slices$acron, levels = c(&#39;gfs&#39;,&#39;pfs&#39;,&#39;tru&#39;,&#39;tor&#39;,&#39;nov&#39;, &#39;nds&#39;,&#39;lex&#39;, &#39;ran&#39;)) slices %&gt;% group_by(acron, Generation) %&gt;% dplyr::summarise( count = n(), na_cnt = sum(is.na(pop_fit_max / DIMENSIONALITY)), min = min(pop_fit_max / DIMENSIONALITY, na.rm = TRUE), median = median(pop_fit_max / DIMENSIONALITY, na.rm = TRUE), mean = mean(pop_fit_max / DIMENSIONALITY, na.rm = TRUE), max = max(pop_fit_max / DIMENSIONALITY, na.rm = TRUE), IQR = IQR(pop_fit_max / DIMENSIONALITY, na.rm = TRUE) ) ## `summarise()` has grouped output by &#39;acron&#39;. You can override using the ## `.groups` argument. ## # A tibble: 14 x 9 ## # Groups: acron [7] ## acron Generation count na_cnt min median mean max IQR ## &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 gfs 50000 50 0 40.7 42.8 42.8 45.7 1.21 ## 2 gfs 40000 50 0 34.9 36.4 36.6 39.3 1.15 ## 3 pfs 50000 50 0 40.7 43.0 42.8 45.0 1.30 ## 4 pfs 40000 50 0 34.4 36.7 36.6 38.1 1.01 ## 5 tru 50000 50 0 17.8 18.0 18.0 18.2 0.118 ## 6 tru 40000 50 0 17.7 17.9 17.9 18.1 0.147 ## 7 tor 50000 50 0 17.9 18.1 18.1 18.3 0.130 ## 8 tor 40000 50 0 17.7 18.0 18.0 18.2 0.115 ## 9 nov 50000 50 0 16.0 17.8 17.8 21.1 1.17 ## 10 nov 40000 50 0 14.3 16.1 16.3 18.1 1.39 ## 11 nds 50000 50 0 14.3 15.0 15.0 15.8 0.327 ## 12 nds 40000 50 0 12.8 13.4 13.4 14.0 0.516 ## 13 lex 50000 50 0 12.0 12.2 12.2 12.5 0.199 ## 14 lex 40000 50 0 12.0 12.2 12.2 12.7 0.132 Truncation selection comparisons. wilcox.test(x = filter(slices, acron == &#39;tru&#39; &amp; Generation == 50000)$pop_fit_max, y = filter(slices, acron == &#39;tru&#39; &amp; Generation == 40000)$pop_fit_max, alternative = &#39;t&#39;) ## ## Wilcoxon rank sum test with continuity correction ## ## data: filter(slices, acron == &quot;tru&quot; &amp; Generation == 50000)$pop_fit_max and filter(slices, acron == &quot;tru&quot; &amp; Generation == 40000)$pop_fit_max ## W = 2037.5, p-value = 5.705e-08 ## alternative hypothesis: true location shift is not equal to 0 Tournament selection comparisons. wilcox.test(x = filter(slices, acron == &#39;tor&#39; &amp; Generation == 50000)$pop_fit_max, y = filter(slices, acron == &#39;tor&#39; &amp; Generation == 40000)$pop_fit_max, alternative = &#39;t&#39;) ## ## Wilcoxon rank sum test with continuity correction ## ## data: filter(slices, acron == &quot;tor&quot; &amp; Generation == 50000)$pop_fit_max and filter(slices, acron == &quot;tor&quot; &amp; Generation == 40000)$pop_fit_max ## W = 2075, p-value = 1.301e-08 ## alternative hypothesis: true location shift is not equal to 0 Lexicase selection comparisons. wilcox.test(x = filter(slices, acron == &#39;lex&#39; &amp; Generation == 50000)$pop_fit_max, y = filter(slices, acron == &#39;lex&#39; &amp; Generation == 40000)$pop_fit_max, alternative = &#39;t&#39;) ## ## Wilcoxon rank sum test with continuity correction ## ## data: filter(slices, acron == &quot;lex&quot; &amp; Generation == 50000)$pop_fit_max and filter(slices, acron == &quot;lex&quot; &amp; Generation == 40000)$pop_fit_max ## W = 1260.5, p-value = 0.945 ## alternative hypothesis: true location shift is not equal to 0 Genotypic fitness sharing comparisons. wilcox.test(x = filter(slices, acron == &#39;gfs&#39; &amp; Generation == 50000)$pop_fit_max, y = filter(slices, acron == &#39;gfs&#39; &amp; Generation == 40000)$pop_fit_max, alternative = &#39;t&#39;) ## ## Wilcoxon rank sum test with continuity correction ## ## data: filter(slices, acron == &quot;gfs&quot; &amp; Generation == 50000)$pop_fit_max and filter(slices, acron == &quot;gfs&quot; &amp; Generation == 40000)$pop_fit_max ## W = 2500, p-value &lt; 2.2e-16 ## alternative hypothesis: true location shift is not equal to 0 Phenotypic fitness sharing comparisons. wilcox.test(x = filter(slices, acron == &#39;pfs&#39; &amp; Generation == 50000)$pop_fit_max, y = filter(slices, acron == &#39;pfs&#39; &amp; Generation == 40000)$pop_fit_max, alternative = &#39;t&#39;) ## ## Wilcoxon rank sum test with continuity correction ## ## data: filter(slices, acron == &quot;pfs&quot; &amp; Generation == 50000)$pop_fit_max and filter(slices, acron == &quot;pfs&quot; &amp; Generation == 40000)$pop_fit_max ## W = 2500, p-value &lt; 2.2e-16 ## alternative hypothesis: true location shift is not equal to 0 Nondominated sorting comparisons. wilcox.test(x = filter(slices, acron == &#39;nds&#39; &amp; Generation == 50000)$pop_fit_max, y = filter(slices, acron == &#39;nds&#39; &amp; Generation == 40000)$pop_fit_max, alternative = &#39;t&#39;) ## ## Wilcoxon rank sum test with continuity correction ## ## data: filter(slices, acron == &quot;nds&quot; &amp; Generation == 50000)$pop_fit_max and filter(slices, acron == &quot;nds&quot; &amp; Generation == 40000)$pop_fit_max ## W = 2500, p-value &lt; 2.2e-16 ## alternative hypothesis: true location shift is not equal to 0 Novelty search comparisons. wilcox.test(x = filter(slices, acron == &#39;nov&#39; &amp; Generation == 50000)$pop_fit_max, y = filter(slices, acron == &#39;nov&#39; &amp; Generation == 40000)$pop_fit_max, alternative = &#39;t&#39;) ## ## Wilcoxon rank sum test with continuity correction ## ## data: filter(slices, acron == &quot;nov&quot; &amp; Generation == 50000)$pop_fit_max and filter(slices, acron == &quot;nov&quot; &amp; Generation == 40000)$pop_fit_max ## W = 2196, p-value = 7.119e-11 ## alternative hypothesis: true location shift is not equal to 0 "],["exploitation-rate-results-1.html", "Chapter 3 Exploitation rate results 3.1 Analysis dependencies 3.2 Performance over time 3.3 Best performance throughout 3.4 Generation satisfactory solution found 3.5 Multi-valley crossing results", " Chapter 3 Exploitation rate results Here we present the results for best performances found by each selection scheme replicate on the ordered exploitation diagnostic. Best performance found refers to the largest average trait score found in a given population. Note that performance values fall between 0.0 and 100.0. 3.1 Analysis dependencies library(ggplot2) library(cowplot) library(dplyr) library(PupillometryR) library(sdamr) 3.2 Performance over time Best performance in a population over time. # data for lines and shading on plots lines = filter(cc_over_time, diagnostic == &#39;ordered_exploitation&#39;) %&gt;% group_by(`Selection\\nScheme`, gen) %&gt;% dplyr::summarise( min = min(pop_fit_max) / DIMENSIONALITY, mean = mean(pop_fit_max) / DIMENSIONALITY, max = max(pop_fit_max) / DIMENSIONALITY ) ## `summarise()` has grouped output by &#39;Selection Scheme&#39;. You can override using ## the `.groups` argument. ggplot(lines, aes(x=gen, y=mean, group = `Selection\\nScheme`, fill =`Selection\\nScheme`, color = `Selection\\nScheme`, shape = `Selection\\nScheme`)) + geom_ribbon(aes(ymin = min, ymax = max), alpha = 0.1) + geom_line(size = 0.5) + geom_point(data = filter(lines, gen %% 2000 == 0 &amp; gen != 0), size = 1.5, stroke = 2.0, alpha = 1.0) + scale_y_continuous( name=&quot;Average trait score&quot;, limits=c(0, 100), breaks=seq(0,100, 20), labels=c(&quot;0&quot;, &quot;20&quot;, &quot;40&quot;, &quot;60&quot;, &quot;80&quot;, &quot;100&quot;) ) + scale_x_continuous( name=&quot;Generations&quot;, limits=c(0, 50000), breaks=c(0, 10000, 20000, 30000, 40000, 50000), labels=c(&quot;0e+4&quot;, &quot;1e+4&quot;, &quot;2e+4&quot;, &quot;3e+4&quot;, &quot;4e+4&quot;, &quot;5e+4&quot;) ) + scale_shape_manual(values=SHAPE)+ scale_colour_manual(values = cb_palette) + scale_fill_manual(values = cb_palette) + ggtitle(&#39;Performance over time&#39;)+ p_theme + theme(legend.title=element_blank()) + guides( shape=guide_legend(ncol=2, title.position = &quot;bottom&quot;), color=guide_legend(ncol=2, title.position = &quot;bottom&quot;), fill=guide_legend(ncol=2, title.position = &quot;bottom&quot;) ) 3.3 Best performance throughout Best performance found throughout 50,000 generations. ### best performance throughout filter(cc_best, col == &#39;pop_fit_max&#39; &amp; diagnostic == &#39;ordered_exploitation&#39;) %&gt;% ggplot(., aes(x = acron, y = val / DIMENSIONALITY, color = acron, fill = acron, shape = acron)) + geom_flat_violin(position = position_nudge(x = .2, y = 0), scale = &#39;width&#39;, alpha = 0.2) + geom_point(position = position_jitter(width = .1), size = 1.5, alpha = 1.0) + geom_boxplot(color = &#39;black&#39;, width = .2, outlier.shape = NA, alpha = 0.0) + scale_y_continuous( name=&quot;Average trait score&quot;, limits=c(-1, 101), breaks=seq(0,100, 20), labels=c(&quot;0&quot;, &quot;20&quot;, &quot;40&quot;, &quot;60&quot;, &quot;80&quot;, &quot;100&quot;) ) + scale_x_discrete( name=&quot;Scheme&quot; )+ scale_shape_manual(values=SHAPE)+ scale_colour_manual(values = cb_palette, ) + scale_fill_manual(values = cb_palette) + ggtitle(&#39;Best performance throughout&#39;)+ p_theme + theme(legend.title=element_blank()) + guides( shape=guide_legend(nrow=2, title.position = &quot;bottom&quot;), color=guide_legend(nrow=2, title.position = &quot;bottom&quot;), fill=guide_legend(nrow=2, title.position = &quot;bottom&quot;) ) 3.3.1 Stats Summary statistics for the performance of the best performance throughout 50,000 generations. #get data &amp; summarize performance = filter(cc_best, col == &#39;pop_fit_max&#39; &amp; diagnostic == &#39;ordered_exploitation&#39;) performance$acron = factor(performance$acron, levels = c(&#39;tru&#39;, &#39;tor&#39;, &#39;lex&#39;,&#39;nds&#39;, &#39;gfs&#39;, &#39;pfs&#39;, &#39;nov&#39;, &#39;ran&#39;)) performance %&gt;% group_by(acron) %&gt;% dplyr::summarise( count = n(), na_cnt = sum(is.na(val)), min = min(val / DIMENSIONALITY, na.rm = TRUE), median = median(val / DIMENSIONALITY, na.rm = TRUE), mean = mean(val / DIMENSIONALITY, na.rm = TRUE), max = max(val / DIMENSIONALITY, na.rm = TRUE), IQR = IQR(val / DIMENSIONALITY, na.rm = TRUE) ) ## # A tibble: 8 x 8 ## acron count na_cnt min median mean max IQR ## &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 tru 50 0 100. 100. 100. 100. 0.00208 ## 2 tor 50 0 99.9 99.9 99.9 99.9 0.00445 ## 3 lex 50 0 99.8 99.8 99.8 99.8 0.0207 ## 4 nds 50 0 23.7 26.0 25.9 27.7 1.17 ## 5 gfs 50 0 19.4 21.0 20.9 22.1 0.970 ## 6 pfs 50 0 12.5 14.1 13.9 15.1 0.871 ## 7 nov 50 0 2.55 3.70 3.80 5.82 0.718 ## 8 ran 50 0 0.319 0.598 0.634 1.26 0.240 KruskalWallis test provides evidence of statistical differences. kruskal.test(val ~ acron, data = performance) ## ## Kruskal-Wallis rank sum test ## ## data: val by acron ## Kruskal-Wallis chi-squared = 392.77, df = 7, p-value &lt; 2.2e-16 Results for post-hoc Wilcoxon rank-sum test with a Bonferroni correction. pairwise.wilcox.test(x = performance$val, g = performance$acron, p.adjust.method = &quot;bonferroni&quot;, paired = FALSE, conf.int = FALSE, alternative = &#39;l&#39;) ## ## Pairwise comparisons using Wilcoxon rank sum test with continuity correction ## ## data: performance$val and performance$acron ## ## tru tor lex nds gfs pfs nov ## tor &lt;2e-16 - - - - - - ## lex &lt;2e-16 &lt;2e-16 - - - - - ## nds &lt;2e-16 &lt;2e-16 &lt;2e-16 - - - - ## gfs &lt;2e-16 &lt;2e-16 &lt;2e-16 &lt;2e-16 - - - ## pfs &lt;2e-16 &lt;2e-16 &lt;2e-16 &lt;2e-16 &lt;2e-16 - - ## nov &lt;2e-16 &lt;2e-16 &lt;2e-16 &lt;2e-16 &lt;2e-16 &lt;2e-16 - ## ran &lt;2e-16 &lt;2e-16 &lt;2e-16 &lt;2e-16 &lt;2e-16 &lt;2e-16 &lt;2e-16 ## ## P value adjustment method: bonferroni 3.4 Generation satisfactory solution found First generation a satisfactory solution is found throughout the 50,000 generations. ### satisfactory solution found filter(cc_ssf, diagnostic == &#39;ordered_exploitation&#39;) %&gt;% ggplot(., aes(x = acron, y = Generations , color = acron, fill = acron, shape = acron)) + geom_flat_violin(position = position_nudge(x = .2, y = 0), scale = &#39;width&#39;, alpha = 0.2) + geom_point(position = position_jitter(width = .1), size = 1.5, alpha = 1.0) + geom_boxplot(color = &#39;black&#39;, width = .2, outlier.shape = NA, alpha = 0.0) + scale_y_continuous( name=&quot;Generation&quot;, limits=c(0, 60001), breaks=c(0, 10000, 20000, 30000, 40000, 50000, 60000), labels=c(&quot;0e+4&quot;, &quot;1e+4&quot;, &quot;2e+4&quot;, &quot;3e+4&quot;, &quot;4e+4&quot;, &quot;5e+4&quot;, &quot;Fail&quot;) ) + scale_x_discrete( name=&quot;Scheme&quot; )+ scale_shape_manual(values=SHAPE)+ scale_colour_manual(values = cb_palette, ) + scale_fill_manual(values = cb_palette) + ggtitle(&#39;Generation satisfactory solution found&#39;)+ p_theme + theme(legend.title=element_blank()) + guides( shape=guide_legend(nrow=2, title.position = &quot;bottom&quot;), color=guide_legend(nrow=2, title.position = &quot;bottom&quot;), fill=guide_legend(nrow=2, title.position = &quot;bottom&quot;) ) 3.4.1 Stats Summary statistics for the first generation a satisfactory solution is found throughout the 50,000 generations. ### Generation satisfactory solution found ssf = filter(cc_ssf, diagnostic == &#39;ordered_exploitation&#39; &amp; Generations &lt; 60000) ssf$acron = factor(ssf$acron, levels = c(&#39;tru&#39;, &#39;tor&#39;, &#39;lex&#39;)) ssf %&gt;% group_by(acron) %&gt;% dplyr::summarise( count = n(), na_cnt = sum(is.na(Generations)), min = min(Generations, na.rm = TRUE), median = median(Generations, na.rm = TRUE), mean = mean(Generations, na.rm = TRUE), max = max(Generations, na.rm = TRUE), IQR = IQR(Generations, na.rm = TRUE) ) ## # A tibble: 3 x 8 ## acron count na_cnt min median mean max IQR ## &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 tru 50 0 14701 15466. 15511. 16280 422. ## 2 tor 50 0 25563 27254. 27122. 28151 714 ## 3 lex 50 0 35240 38918. 38865. 43751 2316. KruskalWallis test provides evidence of difference amoung selection schemes. kruskal.test(Generations ~ acron, data = ssf) ## ## Kruskal-Wallis rank sum test ## ## data: Generations by acron ## Kruskal-Wallis chi-squared = 132.45, df = 2, p-value &lt; 2.2e-16 Results for post-hoc Wilcoxon rank-sum test with a Bonferroni correction. pairwise.wilcox.test(x = ssf$Generations, g = ssf$acron, p.adjust.method = &quot;bonferroni&quot;, paired = FALSE, conf.int = FALSE, alternative = &#39;g&#39;) ## ## Pairwise comparisons using Wilcoxon rank sum test with continuity correction ## ## data: ssf$Generations and ssf$acron ## ## tru tor ## tor &lt;2e-16 - ## lex &lt;2e-16 &lt;2e-16 ## ## P value adjustment method: bonferroni 3.5 Multi-valley crossing results 3.5.1 Performance over time Best performance in a population over time. # data for lines and shading on plots lines = filter(cc_over_time_mvc, diagnostic == &#39;ordered_exploitation&#39;) %&gt;% group_by(`Selection\\nScheme`, gen) %&gt;% dplyr::summarise( min = min(pop_fit_max) / DIMENSIONALITY, mean = mean(pop_fit_max) / DIMENSIONALITY, max = max(pop_fit_max) / DIMENSIONALITY ) ## `summarise()` has grouped output by &#39;Selection Scheme&#39;. You can override using ## the `.groups` argument. ggplot(lines, aes(x=gen, y=mean, group = `Selection\\nScheme`, fill =`Selection\\nScheme`, color = `Selection\\nScheme`, shape = `Selection\\nScheme`)) + geom_ribbon(aes(ymin = min, ymax = max), alpha = 0.1) + geom_line(size = 0.5) + geom_point(data = filter(lines, gen %% 2000 == 0 &amp; gen != 0), size = 1.5, stroke = 2.0, alpha = 1.0) + scale_y_continuous( name=&quot;Average trait score&quot;, limits=c(0, 15), breaks=seq(0,15, 5), labels=c(&quot;0&quot;, &quot;5&quot;, &quot;10&quot;, &quot;15&quot;) ) + scale_x_continuous( name=&quot;Generations&quot;, limits=c(0, 50000), breaks=c(0, 10000, 20000, 30000, 40000, 50000), labels=c(&quot;0e+4&quot;, &quot;1e+4&quot;, &quot;2e+4&quot;, &quot;3e+4&quot;, &quot;4e+4&quot;, &quot;5e+4&quot;) ) + scale_shape_manual(values=SHAPE)+ scale_colour_manual(values = cb_palette) + scale_fill_manual(values = cb_palette) + ggtitle(&#39;Performance over time&#39;)+ p_theme + guides( shape=guide_legend(ncol=2, title.position = &quot;left&quot;), color=guide_legend(ncol=2, title.position = &quot;left&quot;), fill=guide_legend(ncol=2, title.position = &quot;left&quot;) ) 3.5.2 Best performance throughout Best performance found throughout 50,000 generations. ### best performance throughout filter(cc_best_mvc, col == &#39;pop_fit_max&#39; &amp; diagnostic == &#39;ordered_exploitation&#39;) %&gt;% ggplot(., aes(x = acron, y = val / DIMENSIONALITY, color = acron, fill = acron, shape = acron)) + geom_flat_violin(position = position_nudge(x = .2, y = 0), scale = &#39;width&#39;, alpha = 0.2) + geom_point(position = position_jitter(width = .1), size = 1.5, alpha = 1.0) + geom_boxplot(color = &#39;black&#39;, width = .2, outlier.shape = NA, alpha = 0.0) + guides(fill = &quot;none&quot;,color = &#39;none&#39;, shape = &#39;none&#39;) + scale_y_continuous( name=&quot;Average trait score&quot;, limits=c(0, 15), breaks=seq(0,15, 5), labels=c(&quot;0&quot;, &quot;5&quot;, &quot;10&quot;, &quot;15&quot;) ) + scale_x_discrete( name=&quot;Scheme&quot; )+ scale_shape_manual(values=SHAPE)+ scale_colour_manual(values = cb_palette, ) + scale_fill_manual(values = cb_palette) + ggtitle(&#39;Best performance throughout&#39;)+ p_theme + theme(legend.title=element_blank()) + guides( shape=guide_legend(nrow=2, title.position = &quot;bottom&quot;), color=guide_legend(nrow=2, title.position = &quot;bottom&quot;), fill=guide_legend(nrow=2, title.position = &quot;bottom&quot;) ) 3.5.2.1 Stats Summary statistics for the performance of the best performance. #get data &amp; summarize performance = filter(cc_best_mvc, col == &#39;pop_fit_max&#39; &amp; diagnostic == &#39;ordered_exploitation&#39;) performance$acron = factor(performance$acron, levels = c(&#39;gfs&#39;,&#39;pfs&#39;,&#39;tru&#39;,&#39;tor&#39;,&#39;lex&#39;,&#39;nov&#39;, &#39;nds&#39;, &#39;ran&#39;)) performance %&gt;% group_by(acron) %&gt;% dplyr::summarise( count = n(), na_cnt = sum(is.na(val)), min = min(val / DIMENSIONALITY, na.rm = TRUE), median = median(val / DIMENSIONALITY, na.rm = TRUE), mean = mean(val / DIMENSIONALITY, na.rm = TRUE), max = max(val / DIMENSIONALITY, na.rm = TRUE), IQR = IQR(val / DIMENSIONALITY, na.rm = TRUE) ) ## # A tibble: 8 x 8 ## acron count na_cnt min median mean max IQR ## &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 gfs 50 0 10.5 11.6 11.7 12.8 1.04 ## 2 pfs 50 0 9.54 11.0 11.0 12.1 0.553 ## 3 tru 50 0 6.01 8.35 8.19 8.65 0.0922 ## 4 tor 50 0 3.91 7.76 7.52 8.68 1.26 ## 5 lex 50 0 5.20 6.70 6.72 7.91 1.01 ## 6 nov 50 0 2.95 3.71 3.72 4.73 0.476 ## 7 nds 50 0 1.63 1.86 1.85 2.09 0.129 ## 8 ran 50 0 0.263 0.490 0.534 0.968 0.202 KruskalWallis test provides evidence of statistical differences. kruskal.test(val ~ acron, data = performance) ## ## Kruskal-Wallis rank sum test ## ## data: val by acron ## Kruskal-Wallis chi-squared = 380.23, df = 7, p-value &lt; 2.2e-16 Results for post-hoc Wilcoxon rank-sum test with a Bonferroni correction. pairwise.wilcox.test(x = performance$val, g = performance$acron, p.adjust.method = &quot;bonferroni&quot;, paired = FALSE, conf.int = FALSE, alternative = &#39;l&#39;) ## ## Pairwise comparisons using Wilcoxon rank sum test with continuity correction ## ## data: performance$val and performance$acron ## ## gfs pfs tru tor lex nov nds ## pfs 1.6e-06 - - - - - - ## tru &lt; 2e-16 &lt; 2e-16 - - - - - ## tor &lt; 2e-16 &lt; 2e-16 0.0026 - - - - ## lex &lt; 2e-16 &lt; 2e-16 7.7e-14 1.7e-05 - - - ## nov &lt; 2e-16 &lt; 2e-16 &lt; 2e-16 2.4e-16 &lt; 2e-16 - - ## nds &lt; 2e-16 &lt; 2e-16 &lt; 2e-16 &lt; 2e-16 &lt; 2e-16 &lt; 2e-16 - ## ran &lt; 2e-16 &lt; 2e-16 &lt; 2e-16 &lt; 2e-16 &lt; 2e-16 &lt; 2e-16 &lt; 2e-16 ## ## P value adjustment method: bonferroni 3.5.3 Performance comparison Best performances in the population at 40,000 and 50,000 generations. ## Warning: The following aesthetics were dropped during statistical transformation: ## colour, shape ## i This can happen when ggplot fails to infer the correct grouping structure in ## the data. ## i Did you forget to specify a `group` aesthetic or to convert a numerical ## variable into a factor? ## The following aesthetics were dropped during statistical transformation: ## colour, shape ## i This can happen when ggplot fails to infer the correct grouping structure in ## the data. ## i Did you forget to specify a `group` aesthetic or to convert a numerical ## variable into a factor? # 80% and final generation comparison end = filter(cc_over_time_mvc, diagnostic == &#39;ordered_exploitation&#39; &amp; gen == 50000 &amp; acron != &#39;ran&#39;) end$Generation &lt;- factor(end$gen) mid = filter(cc_over_time_mvc, diagnostic == &#39;ordered_exploitation&#39; &amp; gen == 40000 &amp; acron != &#39;ran&#39;) mid$Generation &lt;- factor(mid$gen) mvc_p = ggplot(mid, aes(x = acron, y=pop_fit_max / DIMENSIONALITY, group = acron, shape = Generation)) + geom_point(col = mvc_col[1] , position = position_jitternudge(jitter.width = .03, nudge.x = -0.05), size = 2, alpha = 1.0) + geom_boxplot(position = position_nudge(x = -.15, y = 0), lwd = 0.7, col = mvc_col[1], fill = mvc_col[1], width = .1, outlier.shape = NA, alpha = 0.0) + geom_point(data = end, aes(x = acron, y=pop_fit_max / DIMENSIONALITY), col = mvc_col[2], position = position_jitternudge(jitter.width = .03, nudge.x = 0.05), size = 2, alpha = 1.0) + geom_boxplot(data = end, aes(x = acron, y=pop_fit_max / DIMENSIONALITY), position = position_nudge(x = .15, y = 0), lwd = 0.7, col = mvc_col[2], fill = mvc_col[2], width = .1, outlier.shape = NA, alpha = 0.0) + scale_y_continuous( name=&quot;Average trait score&quot;, limits=c(0, 15), breaks=seq(0,15, 5), labels=c(&quot;0&quot;, &quot;5&quot;, &quot;10&quot;, &quot;15&quot;) ) + scale_x_discrete( name=&quot;Scheme&quot; )+ scale_shape_manual(values=c(0,1))+ scale_colour_manual(values = c(mvc_col[1],mvc_col[2])) + p_theme plot_grid( mvc_p + ggtitle(&quot;Performance comparisons&quot;) + theme(legend.position=&quot;none&quot;), legend, nrow=2, rel_heights = c(1,.05), label_size = TSIZE ) 3.5.3.1 Stats Summary statistics for the performance of the best performance at 40,000 and 50,000 generations. ### performance comparisons and generation slices 40K &amp; 50K slices = filter(cc_over_time_mvc, diagnostic == &#39;ordered_exploitation&#39; &amp; (gen == 50000 | gen == 40000) &amp; acron != &#39;ran&#39;) slices$Generation &lt;- factor(slices$gen, levels = c(50000,40000)) slices$acron = factor(slices$acron, levels = c(&#39;gfs&#39;,&#39;pfs&#39;,&#39;tru&#39;,&#39;tor&#39;,&#39;lex&#39;,&#39;nov&#39;, &#39;nds&#39;, &#39;ran&#39;)) slices %&gt;% group_by(acron, Generation) %&gt;% dplyr::summarise( count = n(), na_cnt = sum(is.na(pop_fit_max / DIMENSIONALITY)), min = min(pop_fit_max / DIMENSIONALITY, na.rm = TRUE), median = median(pop_fit_max / DIMENSIONALITY, na.rm = TRUE), mean = mean(pop_fit_max / DIMENSIONALITY, na.rm = TRUE), max = max(pop_fit_max / DIMENSIONALITY, na.rm = TRUE), IQR = IQR(pop_fit_max / DIMENSIONALITY, na.rm = TRUE) ) ## `summarise()` has grouped output by &#39;acron&#39;. You can override using the ## `.groups` argument. ## # A tibble: 14 x 9 ## # Groups: acron [7] ## acron Generation count na_cnt min median mean max IQR ## &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 gfs 50000 50 0 10.3 11.6 11.6 12.8 1.00 ## 2 gfs 40000 50 0 8.37 9.48 9.45 10.4 0.820 ## 3 pfs 50000 50 0 9.50 10.9 10.8 12.1 0.606 ## 4 pfs 40000 50 0 8.18 9.24 9.23 10.3 0.498 ## 5 tru 50000 50 0 6.01 8.35 8.19 8.65 0.0922 ## 6 tru 40000 50 0 6.01 8.33 8.17 8.63 0.112 ## 7 tor 50000 50 0 3.91 7.76 7.52 8.68 1.26 ## 8 tor 40000 50 0 3.91 7.74 7.49 8.67 1.24 ## 9 lex 50000 50 0 5.19 6.69 6.70 7.91 1.03 ## 10 lex 40000 50 0 5.16 6.63 6.63 7.78 0.852 ## 11 nov 50000 50 0 2.35 3.43 3.38 4.38 0.670 ## 12 nov 40000 50 0 2.27 3.06 3.03 3.99 0.560 ## 13 nds 50000 50 0 1.38 1.63 1.61 1.96 0.239 ## 14 nds 40000 50 0 1.37 1.58 1.58 1.88 0.173 Truncation selection comparisons. wilcox.test(x = filter(slices, acron == &#39;tru&#39; &amp; Generation == 50000)$pop_fit_max, y = filter(slices, acron == &#39;tru&#39; &amp; Generation == 40000)$pop_fit_max, alternative = &#39;t&#39;) ## ## Wilcoxon rank sum test with continuity correction ## ## data: filter(slices, acron == &quot;tru&quot; &amp; Generation == 50000)$pop_fit_max and filter(slices, acron == &quot;tru&quot; &amp; Generation == 40000)$pop_fit_max ## W = 1375, p-value = 0.3907 ## alternative hypothesis: true location shift is not equal to 0 Tournament selection comparisons. wilcox.test(x = filter(slices, acron == &#39;tor&#39; &amp; Generation == 50000)$pop_fit_max, y = filter(slices, acron == &#39;tor&#39; &amp; Generation == 40000)$pop_fit_max, alternative = &#39;t&#39;) ## ## Wilcoxon rank sum test with continuity correction ## ## data: filter(slices, acron == &quot;tor&quot; &amp; Generation == 50000)$pop_fit_max and filter(slices, acron == &quot;tor&quot; &amp; Generation == 40000)$pop_fit_max ## W = 1306.5, p-value = 0.6995 ## alternative hypothesis: true location shift is not equal to 0 Lexicase selection comparisons. wilcox.test(x = filter(slices, acron == &#39;lex&#39; &amp; Generation == 50000)$pop_fit_max, y = filter(slices, acron == &#39;lex&#39; &amp; Generation == 40000)$pop_fit_max, alternative = &#39;t&#39;) ## ## Wilcoxon rank sum test with continuity correction ## ## data: filter(slices, acron == &quot;lex&quot; &amp; Generation == 50000)$pop_fit_max and filter(slices, acron == &quot;lex&quot; &amp; Generation == 40000)$pop_fit_max ## W = 1348, p-value = 0.5015 ## alternative hypothesis: true location shift is not equal to 0 Genotypic fitness sharing comparisons. wilcox.test(x = filter(slices, acron == &#39;gfs&#39; &amp; Generation == 50000)$pop_fit_max, y = filter(slices, acron == &#39;gfs&#39; &amp; Generation == 40000)$pop_fit_max, alternative = &#39;t&#39;) ## ## Wilcoxon rank sum test with continuity correction ## ## data: filter(slices, acron == &quot;gfs&quot; &amp; Generation == 50000)$pop_fit_max and filter(slices, acron == &quot;gfs&quot; &amp; Generation == 40000)$pop_fit_max ## W = 2498, p-value &lt; 2.2e-16 ## alternative hypothesis: true location shift is not equal to 0 Phenotypic fitness sharing comparisons. wilcox.test(x = filter(slices, acron == &#39;pfs&#39; &amp; Generation == 50000)$pop_fit_max, y = filter(slices, acron == &#39;pfs&#39; &amp; Generation == 40000)$pop_fit_max, alternative = &#39;t&#39;) ## ## Wilcoxon rank sum test with continuity correction ## ## data: filter(slices, acron == &quot;pfs&quot; &amp; Generation == 50000)$pop_fit_max and filter(slices, acron == &quot;pfs&quot; &amp; Generation == 40000)$pop_fit_max ## W = 2471, p-value &lt; 2.2e-16 ## alternative hypothesis: true location shift is not equal to 0 Nondominated sorting comparisons. wilcox.test(x = filter(slices, acron == &#39;nds&#39; &amp; Generation == 50000)$pop_fit_max, y = filter(slices, acron == &#39;nds&#39; &amp; Generation == 40000)$pop_fit_max, alternative = &#39;t&#39;) ## ## Wilcoxon rank sum test with continuity correction ## ## data: filter(slices, acron == &quot;nds&quot; &amp; Generation == 50000)$pop_fit_max and filter(slices, acron == &quot;nds&quot; &amp; Generation == 40000)$pop_fit_max ## W = 1413, p-value = 0.2626 ## alternative hypothesis: true location shift is not equal to 0 Novelty search comparisons. wilcox.test(x = filter(slices, acron == &#39;nov&#39; &amp; Generation == 50000)$pop_fit_max, y = filter(slices, acron == &#39;nov&#39; &amp; Generation == 40000)$pop_fit_max, alternative = &#39;t&#39;) ## ## Wilcoxon rank sum test with continuity correction ## ## data: filter(slices, acron == &quot;nov&quot; &amp; Generation == 50000)$pop_fit_max and filter(slices, acron == &quot;nov&quot; &amp; Generation == 40000)$pop_fit_max ## W = 1789, p-value = 0.0002054 ## alternative hypothesis: true location shift is not equal to 0 "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
