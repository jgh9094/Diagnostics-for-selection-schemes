[["index.html", "Diagnostics Supplemental Material Chapter 1 Introduction 1.1 About our supplemental material 1.2 Contributing authors 1.3 Research overview 1.4 Computer Setup 1.5 Experimental setup", " Diagnostics Supplemental Material Jose Guadalupe Hernandez 2023-01-30 Chapter 1 Introduction This is the supplemental material associated with our 2022 ECJ contribution entitled, A suite of diagnostic metrics for characterizing selection schemes. Preprint here. 1.1 About our supplemental material This supplemental material is hosted on GitHub using GitHub pages. The source code and configuration files used to generate this supplemental material can be found in this GitHub repository. We compiled our data analyses and supplemental documentation into this nifty web-accessible book using bookdown. Our supplemental material includes the following paper figures and statistics: Exploitation rate results (Section ??) Ordered exploitation results (Section ??) Contradictory objectives results (Section ??) Multi-path exploration results (Section ??) Multi-valley crossing results (Section ??) Additionally, our supplemental material includes the results from parameter tuning selection schemes: Truncation selection (Section ??) Tournament selection sharing (Section ??) Genotypic fitness sharing (Section ??) Phenotypic fitness sharing (Section ??) Nondominated sorting (Section ??) Novelty search (Section ??) 1.2 Contributing authors Jose Guadalupe Hernandez Alexander Lalejini Charles Ofria 1.3 Research overview Abstract: Evolutionary algorithms typically consist of multiple interacting components, where each component influences an algorithms problem-solving abilities. Understanding how each component of an evolutionary algorithm influences problem-solving success can improve our ability to target particular problem domains. Benchmark suites provide insights into an evolutionary algorithms problem-solving capabilities, but benchmarking problems often have complex search space topologies, making it difficult to isolate and test an algorithms strengths and weaknesses. Our work focuses on diagnosing selection schemes, which identify individuals to contribute genetic material to the next generation, thus driving an evolutionary algorithms search strategy. We introduce four diagnostics for empirically testing the strengths and weaknesses of selection schemes: the exploitation rate diagnostic, ordered exploitation rate diagnostic, contradictory objectives diagnostic, and the multi-path exploration diagnostic. Each diagnostic is a handcrafted search space designed to isolate and measure the relative exploitation and exploration characteristics of selection schemes. Here, we use our diagnostics to evaluate six population selection methods: truncation selection, tournament selection, fitness sharing, lexicase selection, nondominated sorting, and novelty search. Expectedly, tournament and truncation selection excelled at gradient exploitation but poorly explored search spaces, while novelty search excelled at exploration but failed to exploit gradients. Fitness sharing performed poorly across all diagnostics, suggesting poor overall exploitation and exploration abilities. Nondominated sorting was best for maintaining diverse populations comprised of individuals inhabiting multiple optima, but struggled to effectively exploit gradients. Lexicase selection balanced search space exploration without sacrificing exploitation, generally performing well across diagnostics. Our work demonstrates the value of diagnostics for building a deeper understanding of selection schemes, which can then be used to improve or develop new selection methods. 1.4 Computer Setup These analyses were conducted in the following computing environment: print(version) ## _ ## platform x86_64-pc-linux-gnu ## arch x86_64 ## os linux-gnu ## system x86_64, linux-gnu ## status Patched ## major 4 ## minor 2.2 ## year 2022 ## month 11 ## day 10 ## svn rev 83330 ## language R ## version.string R version 4.2.2 Patched (2022-11-10 r83330) ## nickname Innocent and Trusting 1.5 Experimental setup Setting up required variables variables. # includes library(plyr) library(dplyr) ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:plyr&#39;: ## ## arrange, count, desc, failwith, id, mutate, rename, summarise, ## summarize ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union library(tidyverse) ## -- Attaching packages --------------------------------------- tidyverse 1.3.2 ## -- ## v ggplot2 3.4.0 v purrr 1.0.1 ## v tibble 3.1.8 v stringr 1.5.0 ## v tidyr 1.3.0 v forcats 1.0.0 ## v readr 2.1.3 ## -- Conflicts ------------------------------------------ tidyverse_conflicts() -- ## x dplyr::arrange() masks plyr::arrange() ## x purrr::compact() masks plyr::compact() ## x dplyr::count() masks plyr::count() ## x dplyr::desc() masks plyr::desc() ## x dplyr::failwith() masks plyr::failwith() ## x dplyr::filter() masks stats::filter() ## x dplyr::id() masks plyr::id() ## x dplyr::lag() masks stats::lag() ## x dplyr::mutate() masks plyr::mutate() ## x dplyr::rename() masks plyr::rename() ## x dplyr::summarise() masks plyr::summarise() ## x dplyr::summarize() masks plyr::summarize() # graph variables SHAPE = c(5,3,1,2,6,0,4,20,1) cb_palette &lt;- c(&#39;#332288&#39;,&#39;#88CCEE&#39;,&#39;#EE7733&#39;,&#39;#EE3377&#39;,&#39;#117733&#39;,&#39;#882255&#39;,&#39;#44AA99&#39;,&#39;#CCBB44&#39;, &#39;#000000&#39;) mvc_col = c(&#39;#1A85FF&#39;,&#39;#D41159&#39;) TSIZE = 26 p_theme &lt;- theme( text = element_text(size = 28), plot.title = element_text( face = &quot;bold&quot;, size = 22, hjust=0.5), panel.border = element_blank(), panel.grid.minor = element_blank(), legend.title=element_text(size=22), legend.text=element_text(size=23), axis.title = element_text(size=23), axis.text = element_text(size=22), legend.position=&quot;bottom&quot;, panel.background = element_rect(fill = &quot;#f1f2f5&quot;, colour = &quot;white&quot;, size = 0.5, linetype = &quot;solid&quot;) ) ## Warning: The `size` argument of `element_rect()` is deprecated as of ggplot2 3.4.0. ## i Please use the `linewidth` argument instead. # default variables REPLICATES = 50 DIMENSIONALITY = 100 # selection scheme related stuff ACRON = tolower(c(&#39;TRU&#39;,&#39;TOR&#39;,&#39;LEX&#39;,&#39;GFS&#39;,&#39;PFS&#39;,&#39;NDS&#39;,&#39;NOV&#39;,&#39;RAN&#39;)) NAMES = c(&#39;Truncation (tru)&#39;,&#39;Tournament (tor)&#39;,&#39;Lexicase (lex)&#39;, &#39;Genotypic Fitness Sharing (gfs)&#39;,&#39;Phenotypic Fitness Sharing (pfs)&#39;,&#39;Nondominated Sorting (nds)&#39;,&#39;Novelty Search (nov)&#39;,&#39;Random (ran)&#39;) SCHEME = c(&#39;TRUNCATION&#39;,&#39;TOURNAMENT&#39;,&#39;LEXICASE&#39;,&#39;FITSHARING_G&#39;,&#39;FITSHARING_P&#39;,&#39;NONDOMINATEDSORTING&#39;,&#39;NOVELTY&#39;,&#39;TOURNAMENT&#39;) ORDER = c(&#39;Truncation (tru)&#39;,&#39;Tournament (tor)&#39;,&#39;Lexicase (lex)&#39;, &#39;Genotypic Fitness Sharing (gfs)&#39;,&#39;Phenotypic Fitness Sharing (pfs)&#39;,&#39;Nondominated Sorting (nds)&#39;,&#39;Novelty Search (nov)&#39;,&#39;Random (ran)&#39;) # selection scheme parameters TR_LIST = c(1, 2, 4, 8, 16, 32, 64, 128, 256) TS_LIST = c(2, 4, 8, 16, 32, 64, 128, 256) FS_LIST = c(0.0, 0.1, 0.3, 0.6, 1.2, 2.5, 5.0) ND_LIST = c(0.0, 0.1, 0.3, 0.6, 1.2, 2.5, 5.0) NS_LIST = c(1, 2, 4, 8, 15, 30) # selection scheme parameter we are looking for PARAM = c(&#39;8&#39;, &#39;8&#39;, &#39;0.0&#39;, &#39;0.3&#39;, &#39;0.3&#39;, &#39;0.3&#39;, &#39;15&#39;, &#39;1&#39;) # for diagnostic loops DIAGNOSTIC = tolower(c(&#39;EXPLOITATION_RATE&#39;, &#39;ORDERED_EXPLOITATION&#39;, &#39;CONTRADICTORY_OBJECTIVES&#39;, &#39;MULTIPATH_EXPLORATION&#39;)) # data diractory for gh-pages DATA_DIR = &#39;/opt/ECJ-2022-suite-of-diagnostics-for-selection-schemes/DATA-FINAL/&#39; ###################################################################################### # go through each diagnostic and collect over time data for cross comparison (cc) print(&#39;Collecting over time data...&#39;) ## [1] &quot;Collecting over time data...&quot; cc_over_time = data.frame() cc_over_time_mvc = data.frame() for(diagnostic in DIAGNOSTIC) { print(paste(&#39;DIAGNOSTIC&#39;,diagnostic)) for(i in 1:8) { print(paste(&#39;SCHEME:&#39;,SCHEME[i])) dir = paste(DATA_DIR,&#39;NO-MVC/&#39;,SCHEME[i],&#39;/over-time-&#39;,diagnostic,&#39;-&#39;, tolower(SCHEME[i]), &#39;.csv&#39;, sep = &quot;&quot;, collapse = NULL) dir_mvc = paste(DATA_DIR,&#39;MVC/&#39;,SCHEME[i],&#39;/over-time-&#39;,diagnostic,&#39;-&#39;, tolower(SCHEME[i]), &#39;.csv&#39;, sep = &quot;&quot;, collapse = NULL) # read csv df = read.csv(dir, header = TRUE, stringsAsFactors = FALSE) df_mvc = read.csv(dir_mvc, header = TRUE, stringsAsFactors = FALSE) # add names/tags df$acron = ACRON[i] df$`Selection\\nScheme` = NAMES[i] df$diagnostic = diagnostic df_mvc$acron = ACRON[i] df_mvc$`Selection\\nScheme` = NAMES[i] df_mvc$diagnostic = diagnostic # add to cc_over_time data frame if(i == 3) { cc_over_time = rbind(cc_over_time, df) cc_over_time_mvc = rbind(cc_over_time_mvc, df_mvc) } else { cc_over_time = rbind(cc_over_time, filter(df, trt == PARAM[i])) cc_over_time_mvc = rbind(cc_over_time_mvc, filter(df_mvc, trt == PARAM[i])) } } rm(df); rm(df_mvc); rm(dir); rm(dir_mvc) } ## [1] &quot;DIAGNOSTIC exploitation_rate&quot; ## [1] &quot;SCHEME: TRUNCATION&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; ## [1] &quot;SCHEME: LEXICASE&quot; ## [1] &quot;SCHEME: FITSHARING_G&quot; ## [1] &quot;SCHEME: FITSHARING_P&quot; ## [1] &quot;SCHEME: NONDOMINATEDSORTING&quot; ## [1] &quot;SCHEME: NOVELTY&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; ## [1] &quot;DIAGNOSTIC ordered_exploitation&quot; ## [1] &quot;SCHEME: TRUNCATION&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; ## [1] &quot;SCHEME: LEXICASE&quot; ## [1] &quot;SCHEME: FITSHARING_G&quot; ## [1] &quot;SCHEME: FITSHARING_P&quot; ## [1] &quot;SCHEME: NONDOMINATEDSORTING&quot; ## [1] &quot;SCHEME: NOVELTY&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; ## [1] &quot;DIAGNOSTIC contradictory_objectives&quot; ## [1] &quot;SCHEME: TRUNCATION&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; ## [1] &quot;SCHEME: LEXICASE&quot; ## [1] &quot;SCHEME: FITSHARING_G&quot; ## [1] &quot;SCHEME: FITSHARING_P&quot; ## [1] &quot;SCHEME: NONDOMINATEDSORTING&quot; ## [1] &quot;SCHEME: NOVELTY&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; ## [1] &quot;DIAGNOSTIC multipath_exploration&quot; ## [1] &quot;SCHEME: TRUNCATION&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; ## [1] &quot;SCHEME: LEXICASE&quot; ## [1] &quot;SCHEME: FITSHARING_G&quot; ## [1] &quot;SCHEME: FITSHARING_P&quot; ## [1] &quot;SCHEME: NONDOMINATEDSORTING&quot; ## [1] &quot;SCHEME: NOVELTY&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; cc_over_time$`Selection\\nScheme` &lt;- factor(cc_over_time$`Selection\\nScheme`, levels = ORDER) cc_over_time$acron &lt;- factor(cc_over_time$acron, levels = ACRON) cc_over_time$uni_str_pos = cc_over_time$uni_str_pos + cc_over_time$arc_acti_gene - cc_over_time$overlap cc_over_time = subset(cc_over_time, select = -c(trt,pop_fit_avg,archive_cnt,pmin,pareto_cnt,arc_acti_gene,overlap)) cc_over_time_mvc$`Selection\\nScheme` &lt;- factor(cc_over_time$`Selection\\nScheme`, levels = ORDER) cc_over_time_mvc$acron &lt;- factor(cc_over_time$acron, levels = ACRON) cc_over_time_mvc$uni_str_pos = cc_over_time_mvc$uni_str_pos + cc_over_time_mvc$arc_acti_gene - cc_over_time_mvc$overlap cc_over_time_mvc = subset(cc_over_time_mvc, select = -c(trt,pop_fit_avg,archive_cnt,pmin,pareto_cnt,arc_acti_gene,overlap)) ###################################################################################### # go through each diagnostic and collect best over time for cross comparison (cc) cc_best = data.frame() cc_best_mvc = data.frame() for(diagnostic in DIAGNOSTIC) { print(paste(&#39;DIAGNOSTIC&#39;,diagnostic)) for(i in 1:8) { print(paste(&#39;SCHEME:&#39;,SCHEME[i])) dir = paste(DATA_DIR,&#39;NO-MVC/&#39;,SCHEME[i],&#39;/best-&#39;,diagnostic,&#39;-&#39;, tolower(SCHEME[i]), &#39;.csv&#39;, sep = &quot;&quot;, collapse = NULL) dir_mvc = paste(DATA_DIR,&#39;MVC/&#39;,SCHEME[i],&#39;/best-&#39;,diagnostic,&#39;-&#39;, tolower(SCHEME[i]), &#39;.csv&#39;, sep = &quot;&quot;, collapse = NULL) # read csv df = read.csv(dir, header = TRUE, stringsAsFactors = FALSE) df_mvc = read.csv(dir_mvc, header = TRUE, stringsAsFactors = FALSE) # add names/tags df$acron = ACRON[i] df$`Selection\\nScheme` = NAMES[i] df$diagnostic = diagnostic df = subset(df, select = -c(Diagnostic,SEL) ) df_mvc$acron = ACRON[i] df_mvc$`Selection\\nScheme` = NAMES[i] df_mvc$diagnostic = diagnostic df_mvc = subset(df_mvc, select = -c(Diagnostic,SEL) ) # add to cc_over_time data frame if(i == 3) { cc_best = rbind(cc_best, df) cc_best_mvc = rbind(cc_best_mvc, df_mvc) } else { cc_best = rbind(cc_best, filter(df, trt == PARAM[i])) cc_best_mvc = rbind(cc_best_mvc, filter(df_mvc, trt == PARAM[i])) } } rm(df); rm(df_mvc); rm(dir); rm(dir_mvc) } ## [1] &quot;DIAGNOSTIC exploitation_rate&quot; ## [1] &quot;SCHEME: TRUNCATION&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; ## [1] &quot;SCHEME: LEXICASE&quot; ## [1] &quot;SCHEME: FITSHARING_G&quot; ## [1] &quot;SCHEME: FITSHARING_P&quot; ## [1] &quot;SCHEME: NONDOMINATEDSORTING&quot; ## [1] &quot;SCHEME: NOVELTY&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; ## [1] &quot;DIAGNOSTIC ordered_exploitation&quot; ## [1] &quot;SCHEME: TRUNCATION&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; ## [1] &quot;SCHEME: LEXICASE&quot; ## [1] &quot;SCHEME: FITSHARING_G&quot; ## [1] &quot;SCHEME: FITSHARING_P&quot; ## [1] &quot;SCHEME: NONDOMINATEDSORTING&quot; ## [1] &quot;SCHEME: NOVELTY&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; ## [1] &quot;DIAGNOSTIC contradictory_objectives&quot; ## [1] &quot;SCHEME: TRUNCATION&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; ## [1] &quot;SCHEME: LEXICASE&quot; ## [1] &quot;SCHEME: FITSHARING_G&quot; ## [1] &quot;SCHEME: FITSHARING_P&quot; ## [1] &quot;SCHEME: NONDOMINATEDSORTING&quot; ## [1] &quot;SCHEME: NOVELTY&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; ## [1] &quot;DIAGNOSTIC multipath_exploration&quot; ## [1] &quot;SCHEME: TRUNCATION&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; ## [1] &quot;SCHEME: LEXICASE&quot; ## [1] &quot;SCHEME: FITSHARING_G&quot; ## [1] &quot;SCHEME: FITSHARING_P&quot; ## [1] &quot;SCHEME: NONDOMINATEDSORTING&quot; ## [1] &quot;SCHEME: NOVELTY&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; cc_best$acron &lt;- factor(cc_best$acron, levels = ACRON) cc_best = subset(cc_best, select = -c(trt,gen)) cc_best = filter(cc_best, col == &#39;pop_fit_max&#39; | col == &#39;pop_uni_obj&#39;) cc_best_mvc$acron &lt;- factor(cc_best_mvc$acron, levels = ACRON) cc_best_mvc = subset(cc_best_mvc, select = -c(trt,gen)) cc_best_mvc = subset(cc_best_mvc, col == &#39;pop_fit_max&#39; | col == &#39;pop_uni_obj&#39;) ###################################################################################### # get generation a satisfactory solution is found for cross comparison (cc) cc_ssf = data.frame() for(diagnostic in DIAGNOSTIC) { if(diagnostic == &#39;contradictory_objectives&#39; | diagnostic == &#39;multipath_exploration&#39;) {next} print(paste(&#39;DIAGNOSTIC&#39;,diagnostic)) for(i in 1:8) { print(paste(&#39;SCHEME:&#39;,SCHEME[i])) dir = paste(DATA_DIR,&#39;NO-MVC/&#39;,SCHEME[i],&#39;/ssf-&#39;,diagnostic,&#39;-&#39;, tolower(SCHEME[i]), &#39;.csv&#39;, sep = &quot;&quot;, collapse = NULL) # read csv df = read.csv(dir, header = TRUE, stringsAsFactors = FALSE) # add names/tags df$acron = ACRON[i] df$`Selection\\nScheme` = NAMES[i] df$diagnostic = diagnostic df = subset(df, select = -c(Diagnostic,SEL) ) # add to cc_over_time data frame if(i == 3) { cc_ssf = rbind(cc_ssf, df) } else { cc_ssf = rbind(cc_ssf, filter(df, trt == PARAM[i])) } } rm(df); rm(dir); } ## [1] &quot;DIAGNOSTIC exploitation_rate&quot; ## [1] &quot;SCHEME: TRUNCATION&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; ## [1] &quot;SCHEME: LEXICASE&quot; ## [1] &quot;SCHEME: FITSHARING_G&quot; ## [1] &quot;SCHEME: FITSHARING_P&quot; ## [1] &quot;SCHEME: NONDOMINATEDSORTING&quot; ## [1] &quot;SCHEME: NOVELTY&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; ## [1] &quot;DIAGNOSTIC ordered_exploitation&quot; ## [1] &quot;SCHEME: TRUNCATION&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; ## [1] &quot;SCHEME: LEXICASE&quot; ## [1] &quot;SCHEME: FITSHARING_G&quot; ## [1] &quot;SCHEME: FITSHARING_P&quot; ## [1] &quot;SCHEME: NONDOMINATEDSORTING&quot; ## [1] &quot;SCHEME: NOVELTY&quot; ## [1] &quot;SCHEME: TOURNAMENT&quot; cc_ssf$acron &lt;- factor(cc_ssf$acron, levels = ACRON) cc_ssf = subset(cc_ssf, select = -c(trt)) ###################################################################################### # go through each scheme and collect over time data ss_over_time = data.frame() ss_over_time_mvc = data.frame() for(i in 1:8) { # add to cc_over_time data frame if(i == 3 | i == 8) { next } print(SCHEME[i]) for(diagnostic in DIAGNOSTIC) { dir = paste(DATA_DIR,&#39;NO-MVC/&#39;,SCHEME[i],&#39;/over-time-&#39;,diagnostic,&#39;-&#39;, tolower(SCHEME[i]), &#39;.csv&#39;, sep = &quot;&quot;, collapse = NULL) dir_mvc = paste(DATA_DIR,&#39;MVC/&#39;,SCHEME[i],&#39;/over-time-&#39;,diagnostic,&#39;-&#39;, tolower(SCHEME[i]), &#39;.csv&#39;, sep = &quot;&quot;, collapse = NULL) # read csv df = read.csv(dir, header = TRUE, stringsAsFactors = FALSE) df_mvc = read.csv(dir_mvc, header = TRUE, stringsAsFactors = FALSE) # add names/tags df$acron = ACRON[i] df$diagnostic = diagnostic df_mvc$acron = ACRON[i] df_mvc$diagnostic = diagnostic ss_over_time = rbind(ss_over_time, df) ss_over_time_mvc = rbind(ss_over_time_mvc,df_mvc) } rm(df); rm(df_mvc); rm(dir); rm(dir_mvc) } ## [1] &quot;TRUNCATION&quot; ## [1] &quot;TOURNAMENT&quot; ## [1] &quot;FITSHARING_G&quot; ## [1] &quot;FITSHARING_P&quot; ## [1] &quot;NONDOMINATEDSORTING&quot; ## [1] &quot;NOVELTY&quot; # remove unused data ss_over_time$uni_str_pos = ss_over_time$uni_str_pos + ss_over_time$arc_acti_gene - ss_over_time$overlap ss_over_time = subset(ss_over_time, select = -c(pop_fit_avg,archive_cnt,pmin,pareto_cnt,arc_acti_gene,overlap)) ss_over_time_mvc$uni_str_pos = ss_over_time_mvc$uni_str_pos + ss_over_time_mvc$arc_acti_gene - ss_over_time_mvc$overlap ss_over_time_mvc = subset(ss_over_time_mvc, select = -c(pop_fit_avg,archive_cnt,pmin,pareto_cnt,arc_acti_gene,overlap)) ## tournament data frames tor_ot &lt;- data.frame() tor_ot &lt;- filter(ss_over_time, acron == &#39;tor&#39; &amp; trt != 1) tor_ot$T &lt;- factor(tor_ot$trt, levels = TS_LIST) tor_ot &lt;- subset(tor_ot, select = -c(acron,trt)) ## truncation data frames tru_ot &lt;- data.frame() tru_ot &lt;- filter(ss_over_time, acron == &#39;tru&#39;) tru_ot$T &lt;- factor(tru_ot$trt, levels = TR_LIST) tru_ot &lt;- subset(tru_ot, select = -c(acron,trt)) ## genotypic fitness sharing data frames gfs_ot &lt;- data.frame() gfs_ot &lt;- filter(ss_over_time, acron == &#39;gfs&#39;) gfs_ot$Sigma &lt;- factor(gfs_ot$trt, levels = FS_LIST) gfs_ot &lt;- subset(gfs_ot, select = -c(acron,trt)) ## phenotypic fitness sharing data frames pfs_ot &lt;- data.frame() pfs_ot &lt;- filter(ss_over_time, acron == &#39;pfs&#39;) pfs_ot$Sigma &lt;- factor(pfs_ot$trt, levels = FS_LIST) pfs_ot &lt;- subset(pfs_ot, select = -c(acron,trt)) ## nodominated sorting data frames nds_ot &lt;- data.frame() nds_ot &lt;- filter(ss_over_time, acron == &#39;nds&#39;) nds_ot$Sigma &lt;- factor(nds_ot$trt, levels = ND_LIST) nds_ot &lt;- subset(nds_ot, select = -c(acron,trt)) ## novelty search data frames nov_ot &lt;- data.frame() nov_ot &lt;- filter(ss_over_time, acron == &#39;nov&#39; &amp; trt != 0) nov_ot$K &lt;- factor(nov_ot$trt, levels = NS_LIST) nov_ot &lt;- subset(nov_ot, select = -c(acron,trt)) ## tournament data frames mvc tor_ot_mvc &lt;- data.frame() tor_ot_mvc &lt;- filter(ss_over_time_mvc, acron == &#39;tor&#39; &amp; trt != 1) tor_ot_mvc$T &lt;- factor(tor_ot_mvc$trt, levels = TS_LIST) tor_ot_mvc &lt;- subset(tor_ot_mvc, select = -c(acron,trt)) ## truncation data frames mvc tru_ot_mvc &lt;- data.frame() tru_ot_mvc &lt;- filter(ss_over_time_mvc, acron == &#39;tru&#39;) tru_ot_mvc$T &lt;- factor(tru_ot_mvc$trt, levels = TR_LIST) tru_ot_mvc &lt;- subset(tru_ot_mvc, select = -c(acron,trt)) ## genotypic fitness sharing data frames mvc gfs_ot_mvc &lt;- data.frame() gfs_ot_mvc &lt;- filter(ss_over_time_mvc, acron == &#39;gfs&#39;) gfs_ot_mvc$Sigma &lt;- factor(gfs_ot_mvc$trt, levels = FS_LIST) gfs_ot_mvc &lt;- subset(gfs_ot_mvc, select = -c(acron,trt)) ## phenotypic fitness sharing data frames mvc pfs_ot_mvc &lt;- data.frame() pfs_ot_mvc &lt;- filter(ss_over_time_mvc, acron == &#39;pfs&#39;) pfs_ot_mvc$Sigma &lt;- factor(pfs_ot_mvc$trt, levels = FS_LIST) pfs_ot_mvc &lt;- subset(pfs_ot_mvc, select = -c(acron,trt)) ## nodominated sorting data frames mvc nds_ot_mvc &lt;- data.frame() nds_ot_mvc &lt;- filter(ss_over_time_mvc, acron == &#39;nds&#39;) nds_ot_mvc$Sigma &lt;- factor(nds_ot_mvc$trt, levels = ND_LIST) nds_ot_mvc &lt;- subset(nds_ot_mvc, select = -c(acron,trt)) ## novelty search data frames mvc nov_ot_mvc &lt;- data.frame() nov_ot_mvc &lt;- filter(ss_over_time_mvc, acron == &#39;nov&#39; &amp; trt != 0) nov_ot_mvc$K &lt;- factor(nov_ot_mvc$trt, levels = NS_LIST) nov_ot_mvc &lt;- subset(nov_ot_mvc, select = -c(acron,trt)) # clean up rm(ss_over_time_mvc) rm(ss_over_time) ###################################################################################### # go through each scheme and collect best data ss_best = data.frame() ss_best_mvc = data.frame() for(i in 1:8) { # add to cc_best data frame if(i == 3 | i == 8) { next } print(SCHEME[i]) for(diagnostic in DIAGNOSTIC) { dir = paste(DATA_DIR,&#39;NO-MVC/&#39;,SCHEME[i],&#39;/best-&#39;,diagnostic,&#39;-&#39;, tolower(SCHEME[i]), &#39;.csv&#39;, sep = &quot;&quot;, collapse = NULL) dir_mvc = paste(DATA_DIR,&#39;MVC/&#39;,SCHEME[i],&#39;/best-&#39;,diagnostic,&#39;-&#39;, tolower(SCHEME[i]), &#39;.csv&#39;, sep = &quot;&quot;, collapse = NULL) # read csv df = read.csv(dir, header = TRUE, stringsAsFactors = FALSE) df_mvc = read.csv(dir_mvc, header = TRUE, stringsAsFactors = FALSE) # add names/tags df$acron = ACRON[i] df$diagnostic = diagnostic df_mvc$acron = ACRON[i] df_mvc$diagnostic = diagnostic ss_best = rbind(ss_best, df) ss_best_mvc = rbind(ss_best_mvc,df_mvc) } rm(df); rm(df_mvc); rm(dir); rm(dir_mvc) } ## [1] &quot;TRUNCATION&quot; ## [1] &quot;TOURNAMENT&quot; ## [1] &quot;FITSHARING_G&quot; ## [1] &quot;FITSHARING_P&quot; ## [1] &quot;NONDOMINATEDSORTING&quot; ## [1] &quot;NOVELTY&quot; # removed unused data ss_best = subset(ss_best, select = -c(gen)) ss_best = filter(ss_best, col == &#39;pop_fit_max&#39; | col == &#39;pop_uni_obj&#39;) ss_best_mvc = subset(ss_best_mvc, select = -c(gen)) ss_best_mvc = filter(ss_best_mvc, col == &#39;pop_fit_max&#39; | col == &#39;pop_uni_obj&#39;) ## tournament data frames tor_best &lt;- data.frame() tor_best &lt;- filter(ss_best, acron == &#39;tor&#39; &amp; trt != 1) tor_best$T &lt;- factor(tor_best$trt, levels = TS_LIST) tor_best &lt;- subset(tor_best, select = -c(acron,trt)) ## truncation data frames tru_best &lt;- data.frame() tru_best &lt;- filter(ss_best, acron == &#39;tru&#39;) tru_best$T &lt;- factor(tru_best$trt, levels = TR_LIST) tru_best &lt;- subset(tru_best, select = -c(acron,trt)) ## genotypic fitness sharing data frames gfs_best &lt;- data.frame() gfs_best &lt;- filter(ss_best, acron == &#39;gfs&#39;) gfs_best$Sigma &lt;- factor(gfs_best$trt, levels = FS_LIST) gfs_best &lt;- subset(gfs_best, select = -c(acron,trt)) ## phenotypic fitness sharing data frames pfs_best &lt;- data.frame() pfs_best &lt;- filter(ss_best, acron == &#39;pfs&#39;) pfs_best$Sigma &lt;- factor(pfs_best$trt, levels = FS_LIST) pfs_best &lt;- subset(pfs_best, select = -c(acron,trt)) ## nodominated sorting data frames nds_best &lt;- data.frame() nds_best &lt;- filter(ss_best, acron == &#39;nds&#39;) nds_best$Sigma &lt;- factor(nds_best$trt, levels = ND_LIST) nds_best &lt;- subset(nds_best, select = -c(acron,trt)) ## novelty search data frames nov_best &lt;- data.frame() nov_best &lt;- filter(ss_best, acron == &#39;nov&#39; &amp; trt != 0) nov_best$K &lt;- factor(nov_best$trt, levels = NS_LIST) nov_best &lt;- subset(nov_best, select = -c(acron,trt)) ## tournament data frames mvc tor_best_mvc &lt;- data.frame() tor_best_mvc &lt;- filter(ss_best_mvc, acron == &#39;tor&#39; &amp; trt != 1) tor_best_mvc$T &lt;- factor(tor_best_mvc$trt, levels = TS_LIST) tor_best_mvc &lt;- subset(tor_best_mvc, select = -c(acron,trt)) ## truncation data frames mvc tru_best_mvc &lt;- data.frame() tru_best_mvc &lt;- filter(ss_best_mvc, acron == &#39;tru&#39;) tru_best_mvc$T &lt;- factor(tru_best_mvc$trt, levels = TR_LIST) tru_best_mvc &lt;- subset(tru_best_mvc, select = -c(acron,trt)) ## genotypic fitness sharing data frames mvc gfs_best_mvc &lt;- data.frame() gfs_best_mvc &lt;- filter(ss_best_mvc, acron == &#39;gfs&#39;) gfs_best_mvc$Sigma &lt;- factor(gfs_best_mvc$trt, levels = FS_LIST) gfs_best_mvc &lt;- subset(gfs_best_mvc, select = -c(acron,trt)) ## phenotypic fitness sharing data frames mvc pfs_best_mvc &lt;- data.frame() pfs_best_mvc &lt;- filter(ss_best_mvc, acron == &#39;pfs&#39;) pfs_best_mvc$Sigma &lt;- factor(pfs_best_mvc$trt, levels = FS_LIST) pfs_best_mvc &lt;- subset(pfs_best_mvc, select = -c(acron,trt)) ## nodominated sorting data frames mvc nds_best_mvc &lt;- data.frame() nds_best_mvc &lt;- filter(ss_best_mvc, acron == &#39;nds&#39;) nds_best_mvc$Sigma &lt;- factor(nds_best_mvc$trt, levels = ND_LIST) nds_best_mvc &lt;- subset(nds_best_mvc, select = -c(acron,trt)) ## novelty search data frames mvc nov_best_mvc &lt;- data.frame() nov_best_mvc &lt;- filter(ss_best_mvc, acron == &#39;nov&#39; &amp; trt != 0) nov_best_mvc$K &lt;- factor(nov_best_mvc$trt, levels = NS_LIST) nov_best_mvc &lt;- subset(nov_best_mvc, select = -c(acron,trt)) # clean up rm(ss_best_mvc) rm(ss_best) ###################################################################################### # go through each scheme and collect satisfactory solution found #Tournament exp_dir = paste(DATA_DIR,&#39;NO-MVC/TOURNAMENT/ssf-exploitation_rate-tournament.csv&#39;, sep = &quot;&quot;, collapse = NULL) ord_dir = paste(DATA_DIR,&#39;NO-MVC/TOURNAMENT/ssf-ordered_exploitation-tournament.csv&#39;, sep = &quot;&quot;, collapse = NULL) # read csv exp_df = read.csv(exp_dir, header = TRUE, stringsAsFactors = FALSE) ord_df = read.csv(ord_dir, header = TRUE, stringsAsFactors = FALSE) # remove data exp_df = subset(exp_df, select = -c(SEL)) exp_df = filter(exp_df, trt != 1) ord_df = subset(ord_df, select = -c(SEL)) ord_df = filter(ord_df, trt != 1) # combine tru_ssf = rbind(exp_df,ord_df) #Truncation exp_dir = paste(DATA_DIR,&#39;NO-MVC/TRUNCATION/ssf-exploitation_rate-truncation.csv&#39;, sep = &quot;&quot;, collapse = NULL) ord_dir = paste(DATA_DIR,&#39;NO-MVC/TRUNCATION/ssf-ordered_exploitation-truncation.csv&#39;, sep = &quot;&quot;, collapse = NULL) # read csv exp_df = read.csv(exp_dir, header = TRUE, stringsAsFactors = FALSE) ord_df = read.csv(ord_dir, header = TRUE, stringsAsFactors = FALSE) # remove data exp_df = subset(exp_df, select = -c(SEL)) exp_df = filter(exp_df, trt != 1) ord_df = subset(ord_df, select = -c(SEL)) ord_df = filter(ord_df, trt != 1) # combine tru_ssf = rbind(exp_df,ord_df) #final clean up rm(i,exp_dir,ord_dir,exp_df,ord_df) "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
